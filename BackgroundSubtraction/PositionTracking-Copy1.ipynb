{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream video and subtract background model and track rodent position\n",
    "This program calculates pixel distance away from two objects and time spent with these objects\n",
    "\n",
    "Controls for background model estimation:\n",
    "1. Background model can be reestimated by pressing space bar. It will continue to use the video to estimate the background model unitl space bar is pressed again. \n",
    "2. +|- keys can be pressed to further filter out white blobs in the foreground streaming video.\n",
    "3. 's' can be pressend to toggle shadows\n",
    "\n",
    "Cell Functionality:\n",
    "1. Imports\n",
    "2. Find homography\n",
    "3. Find pixel locations of object and set exploration classification radius\n",
    "4. Setup background model if not estimated in 2. \n",
    "5. Convert video file so it is compressed and easier to process\n",
    "6. Chop off part of the video\n",
    "7. Position tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find homography\n",
    "source_pts = np.array([[100, 90], [475, 70], [425, 370], [75, 470]], dtype = 'float32') #pixels!\n",
    "dst_pts = np.array([[0, 0], [100, 0], [80, 80], [0, 100]], dtype = 'float32') #cm\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(source_pts, dst_pts, cv2.RANSAC, 5.0) #not sure what the 5.0 is really doing seems to work though\n",
    "POINTMOO = np.array([[75,470]],dtype = 'float32')\n",
    "POINTMOO = np.array([POINTMOO])\n",
    "dst_pt = cv2.perspectiveTransform(POINTMOO, homography_matrix)\n",
    "#print(dst_pt[0][0][0])\n",
    "#print(dst_pt[0][0][1])\n",
    "#print(dst_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #Locations of objects and distance thresholds (how close does the rat have to be to be near it)\n",
    "familiarObject_center_x = 380\n",
    "familiarObject_center_y = 160\n",
    "realWorld_famObj_center = cv2.perspectiveTransform(np.array([np.array([[familiarObject_center_x,familiarObject_center_y]], dtype='float32')]), homography_matrix)\n",
    "familiarObject_center_x_realWorld = realWorld_famObj_center[0][0][0]\n",
    "familiarObject_center_y_realWorld = realWorld_famObj_center[0][0][1]\n",
    "DistanceThreshold_familiarObject = 22;\n",
    "numFrames_FamiliarObject = 0;\n",
    "\n",
    "novelObject_center_x = 210\n",
    "novelObject_center_y = 320\n",
    "realWorld_novelObj_center = cv2.perspectiveTransform(np.array([np.array([[novelObject_center_x,novelObject_center_y]],dtype='float32')]), homography_matrix)\n",
    "novelObject_center_x_realWorld = realWorld_novelObj_center[0][0][0]\n",
    "novelObject_center_y_realWorld = realWorld_novelObj_center[0][0][1]\n",
    "DistanceThrehshold_NovelObject = 22;\n",
    "numFrames_NovelObject = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup for background model and foreground tracking\n",
    "if 'fgbg' not in locals():\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "    \n",
    "morph_size = 2\n",
    "shadowValue = 127\n",
    "learnBG = False\n",
    "showShadow = False\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## convert a video file to an .mp4 using imageio (ffmpeg) and default settings---usually much smaller file size\\n\\nimport imageio\\nimport os\\nfrom tqdm import tqdm_notebook\\n\\ninfile = \\'tornado_125mg_rot_10_6_16_pt2.mov\\'\\n\\nverbose = False\\n\\ntry:\\n   reader = imageio.get_reader(infile)\\n   fps = reader.get_meta_data()[\\'fps\\']\\n   \\n   if verbose:\\n       print(\\'input video file has a framerate of {} fps\\'.format(fps))\\n   \\n   try:\\n       writer = imageio.get_writer(\\'converted.mp4\\', fps=fps,)\\n       for im in tqdm_notebook(reader, desc=\\'converting video\\'):\\n           writer.append_data(im)\\n\\n       writer.close()\\n       print(\\'conversion complete!\\')\\n   \\n   except:\\n       print(\"something went wrong!\")\\nexcept:\\n   print(\"something went wrong; couldn\\'t open file?...\")\\n   \\n# TODO: rename files (unless explicitly told not to)\\nsplits = infile.split(\\'.\\')\\nnewName = splits[0] + \\'-orig.\\' + splits[1]\\nos.rename(infile, newName)\\nos.rename(\\'converted.mp4\\', infile)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " '''\n",
    "## convert a video file to an .mp4 using imageio (ffmpeg) and default settings---usually much smaller file size\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "infile = 'tornado_125mg_rot_10_6_16_pt2.mov'\n",
    "\n",
    "verbose = False\n",
    "\n",
    "try:\n",
    "    reader = imageio.get_reader(infile)\n",
    "    fps = reader.get_meta_data()['fps']\n",
    "    \n",
    "    if verbose:\n",
    "        print('input video file has a framerate of {} fps'.format(fps))\n",
    "    \n",
    "    try:\n",
    "        writer = imageio.get_writer('converted.mp4', fps=fps,)\n",
    "        for im in tqdm_notebook(reader, desc='converting video'):\n",
    "            writer.append_data(im)\n",
    "\n",
    "        writer.close()\n",
    "        print('conversion complete!')\n",
    "    \n",
    "    except:\n",
    "        print(\"something went wrong!\")\n",
    "except:\n",
    "    print(\"something went wrong; couldn't open file?...\")\n",
    "    \n",
    "# TODO: rename files (unless explicitly told not to)\n",
    "splits = infile.split('.')\n",
    "newName = splits[0] + '-orig.' + splits[1]\n",
    "os.rename(infile, newName)\n",
    "os.rename('converted.mp4', infile)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#chop off first X seconds\\nimport subprocess\\nseconds = \"22\"\\nsubprocess.call([\\'ffmpeg\\',\\'-i\\', \\'Round2/Day3/Test-2-cropped.mkv\\', \\'-ss\\', seconds, \\'Round2/Day3/Test-2-cropped1.mkv\\'])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#chop off first X seconds\n",
    "import subprocess\n",
    "seconds = \"22\"\n",
    "subprocess.call(['ffmpeg','-i', 'Round2/Day3/Test-2-cropped.mkv', '-ss', seconds, 'Round2/Day3/Test-2-cropped1.mkv'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual work happens below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video file length is 675.2333333333333 seconds\n",
      "input video file has a framerate of 30.0 fps\n",
      "background learning ON\n",
      "shadows ON\n",
      "shadows OFF\n",
      "background learning OFF\n",
      "background learning ON\n",
      "background learning OFF\n",
      "background learning ON\n",
      "background learning OFF\n",
      "background learning ON\n",
      "background learning OFF\n"
     ]
    }
   ],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('Round2/Day3/Test-2-cropped1.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "# cv2.morph_open\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "        \n",
    "#         xval = []\n",
    "#         yval = []\n",
    "        data = ratBlob.coords\n",
    "        moo = data.reshape(data.size)\n",
    "        xval = moo[::2]\n",
    "        yval = moo[1::2]\n",
    "#         for point in np.nditer(data):\n",
    "#             xval.append(point[0])\n",
    "#             yval.append(point[1])\n",
    "#         xarray = nd.array(xval)\n",
    "#         yarray = nd.array(yval)\n",
    "        coeffs = np.polyfit(np.array(xval), np.array(yval), 1)\n",
    "#         line = coeffs[1]*xval + coeffs[2]\n",
    "        largestx = max(xval)\n",
    "        smallestx = min(xval)\n",
    "        cv2.arrowedLine(im, (int(np.polyval(coeffs, int(smallestx))), int(smallestx)), (int(np.polyval(coeffs, int(largestx))), int(largestx)), (255,0,0), 2)\n",
    "#         cv2.arrowedLine(im, (int(smallestx), int(np.polyval(coeffs, int(smallestx)))), (int(largestx), int(np.polyval(coeffs, int(largestx)))), (255,0,0), 2)\n",
    "#         cv2.arrowedLine(im, (int(x0), int(y0)), (int(smallestx), int(np.polyval(coeffs, int(smallestx)))), (255,0,0), 2)\n",
    "#         xFit = np.linspace(1, largestx, 10)\n",
    "#         yFit = np.polyval(coeffs, xFit)\n",
    "        \n",
    "#         pltim = plt.imread('Round2/Day3/Test-2-cropped.mkv')\n",
    "#         implot = plt.imshow(pltim)\n",
    "    \n",
    "#         plt.plot(xFit, yFit, 'b--')\n",
    "\n",
    "#         plt.show()\n",
    "    \n",
    "#MOOO\n",
    "        #Contour and line of best fit\n",
    "#         _, contours, _ = cv2.findContours(fgmask,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         #print(contours[0])\n",
    "#         #print(ratContours)\n",
    "#         rows, cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(contours[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx) + y)\n",
    "#         cv2.drawContours(im, contours, 0,(0,255,0),2)\n",
    "#         cv2.arrowedLine(im,(cols-1,righty),(0,lefty),(255,0,0),2)\n",
    "\n",
    "        #draw tracking \"dot\"\n",
    "        cv2.circle(im,(int(x0),int(y0)),10,(255,255,255),-11)\n",
    "        cv2.circle(im,(int(x0),int(y0)),11,(0,0,255),1) # draw circle\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "        cv2.circle(im,(int(x0),int(y0)),1,(0,255,0),1) # draw center\n",
    "        #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        # 'dot' location of familiar object\n",
    "        cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        # 'dot' location of novel object\n",
    "        cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "        distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "        distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "        if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "            numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "            cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "        if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "            numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "            cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "            \n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(bg)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n",
    "timeSpentFamObject = numFrames_FamiliarObject/fps\n",
    "timeSpentNovObject = numFrames_NovelObject/fps\n",
    "\n",
    "timeSpent = ('Familiar', 'Novel')\n",
    "n_groups = len(timeSpent)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.1\n",
    "\n",
    "plt.bar(index, [timeSpentFamObject, timeSpentNovObject], bar_width, color='blue', align='center', alpha=0.6)\n",
    "\n",
    "plt.title(\"Time Spent with Objects\")\n",
    "plt.xticks(index, ('Familiar', 'Novel'))\n",
    "plt.xlabel(\"Object\")\n",
    "plt.ylabel(\"Time (Seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cow = data[0:10]\n",
    "cow.squeeze()\n",
    "np.savez(\"cow.npz\",ariel=cow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cow.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moo = cow.reshape(20)\n",
    "moo[1::2]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
