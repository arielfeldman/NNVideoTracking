{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours, LineModelND, ransac\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find homography\n",
    "source_pts = np.array([[100, 90], [475, 70], [425, 370], [75, 470]], dtype = 'float32') #pixels!\n",
    "dst_pts = np.array([[0, 0], [100, 0], [80, 80], [0, 100]], dtype = 'float32') #cm\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(source_pts, dst_pts, cv2.RANSAC, 5.0) #not sure what the 5.0 is really doing seems to work though\n",
    "POINTMOO = np.array([[75,470]],dtype = 'float32')\n",
    "POINTMOO = np.array([POINTMOO])\n",
    "dst_pt = cv2.perspectiveTransform(POINTMOO, homography_matrix)\n",
    "#print(dst_pt[0][0][0])\n",
    "#print(dst_pt[0][0][1])\n",
    "#print(dst_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Locations of objects and distance thresholds (how close does the rat have to be to be near it)\n",
    "familiarObject_center_x = 380\n",
    "familiarObject_center_y = 160\n",
    "realWorld_famObj_center = cv2.perspectiveTransform(np.array([np.array([[familiarObject_center_x,familiarObject_center_y]], dtype='float32')]), homography_matrix)\n",
    "familiarObject_center_x_realWorld = realWorld_famObj_center[0][0][0]\n",
    "familiarObject_center_y_realWorld = realWorld_famObj_center[0][0][1]\n",
    "DistanceThreshold_familiarObject = 22;\n",
    "numFrames_FamiliarObject = 0;\n",
    "\n",
    "novelObject_center_x = 210\n",
    "novelObject_center_y = 320\n",
    "realWorld_novelObj_center = cv2.perspectiveTransform(np.array([np.array([[novelObject_center_x,novelObject_center_y]],dtype='float32')]), homography_matrix)\n",
    "novelObject_center_x_realWorld = realWorld_novelObj_center[0][0][0]\n",
    "novelObject_center_y_realWorld = realWorld_novelObj_center[0][0][1]\n",
    "DistanceThrehshold_NovelObject = 22;\n",
    "numFrames_NovelObject = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup for background model and foreground tracking\n",
    "if 'fgbg' not in locals():\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "    \n",
    "morph_size = 2\n",
    "shadowValue = 127\n",
    "learnBG = False\n",
    "showShadow = False\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Convert Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## convert a video file to an .mp4 using imageio (ffmpeg) and default settings---usually much smaller file size\\n\\nimport imageio\\nimport os\\nfrom tqdm import tqdm_notebook\\n\\ninfile = \\'tornado_125mg_rot_10_6_16_pt2.mov\\'\\n\\nverbose = False\\n\\ntry:\\n    reader = imageio.get_reader(infile)\\n    fps = reader.get_meta_data()[\\'fps\\']\\n    \\n    if verbose:\\n        print(\\'input video file has a framerate of {} fps\\'.format(fps))\\n    \\n    try:\\n        writer = imageio.get_writer(\\'converted.mp4\\', fps=fps,)\\n        for im in tqdm_notebook(reader, desc=\\'converting video\\'):\\n            writer.append_data(im)\\n\\n        writer.close()\\n        print(\\'conversion complete!\\')\\n    \\n    except:\\n        print(\"something went wrong!\")\\nexcept:\\n    print(\"something went wrong; couldn\\'t open file?...\")\\n    \\n# TODO: rename files (unless explicitly told not to)\\nsplits = infile.split(\\'.\\')\\nnewName = splits[0] + \\'-orig.\\' + splits[1]\\nos.rename(infile, newName)\\nos.rename(\\'converted.mp4\\', infile)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## convert a video file to an .mp4 using imageio (ffmpeg) and default settings---usually much smaller file size\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "infile = 'tornado_125mg_rot_10_6_16_pt2.mov'\n",
    "\n",
    "verbose = False\n",
    "\n",
    "try:\n",
    "    reader = imageio.get_reader(infile)\n",
    "    fps = reader.get_meta_data()['fps']\n",
    "    \n",
    "    if verbose:\n",
    "        print('input video file has a framerate of {} fps'.format(fps))\n",
    "    \n",
    "    try:\n",
    "        writer = imageio.get_writer('converted.mp4', fps=fps,)\n",
    "        for im in tqdm_notebook(reader, desc='converting video'):\n",
    "            writer.append_data(im)\n",
    "\n",
    "        writer.close()\n",
    "        print('conversion complete!')\n",
    "    \n",
    "    except:\n",
    "        print(\"something went wrong!\")\n",
    "except:\n",
    "    print(\"something went wrong; couldn't open file?...\")\n",
    "    \n",
    "# TODO: rename files (unless explicitly told not to)\n",
    "splits = infile.split('.')\n",
    "newName = splits[0] + '-orig.' + splits[1]\n",
    "os.rename(infile, newName)\n",
    "os.rename('converted.mp4', infile)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#chop off first X seconds\\nimport subprocess\\nseconds = \"19\"\\nsubprocess.call([\\'ffmpeg\\',\\'-i\\', \\'Round2/Day3/Test-2.mkv\\', \\'-ss\\', seconds, \\'Round2/Day3/Test-2-cropped.mkv\\'])\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#chop off first X seconds\n",
    "import subprocess\n",
    "seconds = \"19\"\n",
    "subprocess.call(['ffmpeg','-i', 'Round2/Day3/Test-2.mkv', '-ss', seconds, 'Round2/Day3/Test-2-cropped.mkv'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Work Happens Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video file length is 697.2333333333333 seconds\n",
      "input video file has a framerate of 30.0 fps\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Line parallel to axis 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9dce8609b804>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m#generate coordinates of estimated models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mline_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mline_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;31m#         line_y_robust = model_robust.predict_y(line_x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kemerelab/anaconda3/lib/python3.5/site-packages/skimage/measure/fit.py\u001b[0m in \u001b[0;36mpredict_y\u001b[1;34m(self, x, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \"\"\"\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kemerelab/anaconda3/lib/python3.5/site-packages/skimage/measure/fit.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, axis, params)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[1;31m# line parallel to axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Line parallel to axis %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Line parallel to axis 0"
     ]
    }
   ],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('/home/kemerelab/Test-2-cropped1.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "        \n",
    "        np.random.seed(seed = 1)\n",
    "        \n",
    "        #generate coordinates of line\n",
    "        minr, minc, maxr, maxc = ratBlob.bbox\n",
    "        width = ((int(maxc) - int(minc)) + 1)\n",
    "        height = ((int(maxr) - int(minr)) + 1)\n",
    "        for x in range(0, 400):\n",
    "            y = (int(height/width) * (x - x0)) + y0\n",
    "        data = ratBlob.coords\n",
    "        \n",
    "        #fit line using all data\n",
    "        model = LineModelND()\n",
    "        model.estimate(data)\n",
    "        \n",
    "#         #robustly fit line only using inlier data with RANSAC algorithm\n",
    "#         model_robust, inliers = ransac(data, LineModelND, min_samples = 2, residual_threshold = 1, max_trials = 1000)\n",
    "#         outliers = inliers == False\n",
    "        \n",
    "        #generate coordinates of estimated models\n",
    "        line_x = np.arange(0, width)\n",
    "        line_y = model.predict_y(line_x)\n",
    "#         line_y_robust = model_robust.predict_y(line_x)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(data[inliers, 0], data[inliers, 1], '.b', alpha = 0.6, label = 'Inlier data')\n",
    "        ax.plot(data[outliers, 0], data[outliers, 1], '.r', alpha = 0.6, label = 'Outlier data')\n",
    "        ax.plot(line_x, line_y, '-k', label = 'Line model from all data')\n",
    "#         ax.plot(line_x, line_y_robust, '-b', label = 'Robust line model')\n",
    "        ax.legend (loc = 'lower left')\n",
    "        plt.show()\n",
    "#MOOO\n",
    "        #Contour and line of best fit\n",
    "#         _, contours, _ = cv2.findContours(fgmask,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         #print(contours[0])\n",
    "#         #print(ratContours)\n",
    "#         rows, cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(contours[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx) + y)\n",
    "#         cv2.drawContours(im, contours, 0,(0,255,0),2)\n",
    "#         cv2.arrowedLine(im,(cols-1,righty),(0,lefty),(255,0,0),2)\n",
    "\n",
    "        #draw tracking \"dot\"\n",
    "        cv2.circle(im,(int(x0),int(y0)),10,(255,255,255),-11)\n",
    "        cv2.circle(im,(int(x0),int(y0)),11,(0,0,255),1) # draw circle\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "        cv2.circle(im,(int(x0),int(y0)),1,(0,255,0),1) # draw center\n",
    "        #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        # 'dot' location of familiar object\n",
    "        cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        # 'dot' location of novel object\n",
    "        cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "        distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "        distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "        if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "            numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "            cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "        if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "            numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "            cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "            \n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n",
    "timeSpentFamObject = numFrames_FamiliarObject/fps\n",
    "timeSpentNovObject = numFrames_NovelObject/fps\n",
    "\n",
    "timeSpent = ('Familiar', 'Novel')\n",
    "n_groups = len(timeSpent)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.1\n",
    "\n",
    "plt.bar(index, [timeSpentFamObject, timeSpentNovObject], bar_width, color='blue', align='center', alpha=0.6)\n",
    "\n",
    "plt.title(\"Time Spent with Objects\")\n",
    "plt.xticks(index, ('Familiar', 'Novel'))\n",
    "plt.xlabel(\"Object\")\n",
    "plt.ylabel(\"Time (Seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-31b57ae69c4f>, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-31b57ae69c4f>\"\u001b[1;36m, line \u001b[1;32m78\u001b[0m\n\u001b[1;33m    print \"test_err min\" , test_err.min()\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours, LineModelND, ransac\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('/home/kemerelab/Test-2-cropped1.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "    \n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "        \n",
    "        data = ratBlob.coords\n",
    "def ransac(data, model, n, k, t, d, debug = False, return_all = False):\n",
    "    \"\"\"\n",
    "    fit model parameters to data using the RANSAC algorithm\n",
    "    \"\"\"\n",
    "    iterations = 0\n",
    "    bestfit = None\n",
    "    besterr = numpy.inf\n",
    "    best_inlier_idxs = None\n",
    "    while iterations < k:\n",
    "        maybe_idxs, test_idxs = random_partition(n,data.shape[0])\n",
    "        maybeinliers = data[maybe_idxs,:]\n",
    "        test_points = data[test_idxs]\n",
    "        maybemodel = model.fit(maybeinliers)\n",
    "        test_err = model.get_error( test_points, maybemodel)\n",
    "        also_idxs = test_idxs[test_err < t] # select indices of rows with accepted points\n",
    "        alsoinliers = data[also_idxs,:]\n",
    "        if debug:\n",
    "            print \"test_err min\" , test_err.min()\n",
    "            print 'test_err.max()' , test_err.max()\n",
    "            print 'numpy.mean(test_err)' , numpy.mean(test_err)\n",
    "            print 'iteration %d:len(alsoinliers) = %d'%(\n",
    "                iterations,len(alsoinliers))\n",
    "        if len(alsoinliers) > d:\n",
    "            betterdata = numpy.concatenate( (maybeinliers, alsoinliers) )\n",
    "            bettermodel = model.fit(betterdata)\n",
    "            better_errs = model.get_error( betterdata, bettermodel)\n",
    "            thiserr = numpy.mean( better_errs )\n",
    "            if thiserr < besterr:\n",
    "                bestfit = bettermodel\n",
    "                besterr = thiserr\n",
    "                best_inlier_idxs = numpy.concatenate( (maybe_idxs, also_idxs) )\n",
    "        iterations+=1\n",
    "    if bestfit is None:\n",
    "        raise ValueError(\"did not meet fit acceptance criteria\")\n",
    "    if return_all:\n",
    "        return bestfit, {'inliers':best_inlier_idxs}\n",
    "    else:\n",
    "        return bestfit\n",
    "        \n",
    "def random_partition(n,n_data):\n",
    "    \"\"\"return n random rows of data (and also the other len(data)-n rows)\"\"\"\n",
    "    all_idxs = numpy.arange( n_data )\n",
    "    numpy.random.shuffle(all_idxs)\n",
    "    idxs1 = all_idxs[:n]\n",
    "    idxs2 = all_idxs[n:]\n",
    "    return idxs1, idxs2\n",
    "  \n",
    "class LinearLeastSquaresModel:\n",
    "    \"\"\"linear system solved using linear least squares\n",
    "  \n",
    "    This class serves as an example that fulfills the model interface\n",
    "    needed by the ransac() function.\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self,input_columns,output_columns,debug=False):\n",
    "        self.input_columns = input_columns\n",
    "        self.output_columns = output_columns\n",
    "        self.debug = debug\n",
    "    def fit(self, data):\n",
    "        A = numpy.vstack([data[:,i] for i in self.input_columns]).T\n",
    "        B = numpy.vstack([data[:,i] for i in self.output_columns]).T\n",
    "        x,resids,rank,s = scipy.linalg.lstsq(A,B)\n",
    "        return x\n",
    "    def get_error( self, data, model):\n",
    "        A = numpy.vstack([data[:,i] for i in self.input_columns]).T\n",
    "        B = numpy.vstack([data[:,i] for i in self.output_columns]).T\n",
    "        B_fit = scipy.dot(A,model)\n",
    "        err_per_point = numpy.sum((B-B_fit)**2,axis=1) # sum squared error per row\n",
    "        return err_per_point\n",
    "          \n",
    "def test():\n",
    "    # generate perfect input data\n",
    "    n_samples = 500\n",
    "    n_inputs = 1\n",
    "    n_outputs = 1\n",
    "    A_exact = 20*numpy.random.random((n_samples,n_inputs) )\n",
    "    perfect_fit = 60*numpy.random.normal(size=(n_inputs,n_outputs) ) # the model\n",
    "    B_exact = scipy.dot(A_exact,perfect_fit)\n",
    "    assert B_exact.shape == (n_samples,n_outputs)\n",
    "        \n",
    "    # add a little gaussian noise (linear least squares alone should handle this well)\n",
    "    A_noisy = A_exact + numpy.random.normal(size=A_exact.shape )\n",
    "    B_noisy = B_exact + numpy.random.normal(size=B_exact.shape )\n",
    "  \n",
    "    if 1:\n",
    "    # add some outliers\n",
    "        n_outliers = 100\n",
    "        all_idxs = numpy.arange( A_noisy.shape[0] )\n",
    "        numpy.random.shuffle(all_idxs)\n",
    "        outlier_idxs = all_idxs[:n_outliers]\n",
    "        non_outlier_idxs = all_idxs[n_outliers:]\n",
    "        A_noisy[outlier_idxs] =  20*numpy.random.random((n_outliers,n_inputs) )\n",
    "        B_noisy[outlier_idxs] = 50*numpy.random.normal(size=(n_outliers,n_outputs) )\n",
    "            \n",
    "    # setup model\n",
    "  \n",
    "    all_data = numpy.hstack( (A_noisy,B_noisy) )\n",
    "    input_columns = range(n_inputs) # the first columns of the array\n",
    "    output_columns = [n_inputs+i for i in range(n_outputs)] # the last columns of the array\n",
    "    debug = False\n",
    "    model = LinearLeastSquaresModel(input_columns,output_columns,debug=debug)\n",
    "  \n",
    "    linear_fit,resids,rank,s = scipy.linalg.lstsq(all_data[:,input_columns],\n",
    "                                                      all_data[:,output_columns])\n",
    "  \n",
    "    # run RANSAC algorithm\n",
    "    ransac_fit, ransac_data = ransac(all_data,model,\n",
    "                                    50, 1000, 7e3, 300, # misc. parameters\n",
    "                                    debug=debug,return_all=True)\n",
    "    if 1:\n",
    "        import pylab\n",
    "  \n",
    "        sort_idxs = numpy.argsort(A_exact[:,0])\n",
    "        A_col0_sorted = A_exact[sort_idxs] # maintain as rank-2 array\n",
    "  \n",
    "        if 1:\n",
    "            pylab.plot( A_noisy[:,0], B_noisy[:,0], 'k.', label='data' )\n",
    "            pylab.plot( A_noisy[ransac_data['inliers'],0], B_noisy[ransac_data['inliers'],0], 'bx', label='RANSAC data' )\n",
    "        else:\n",
    "            pylab.plot( A_noisy[non_outlier_idxs,0], B_noisy[non_outlier_idxs,0], 'k.', label='noisy data' )\n",
    "            pylab.plot( A_noisy[outlier_idxs,0], B_noisy[outlier_idxs,0], 'r.', label='outlier data' )\n",
    "            pylab.plot( A_col0_sorted[:,0],\n",
    "                        numpy.dot(A_col0_sorted,ransac_fit)[:,0],\n",
    "                        label='RANSAC fit' )\n",
    "            pylab.plot( A_col0_sorted[:,0],\n",
    "                        numpy.dot(A_col0_sorted,perfect_fit)[:,0],\n",
    "                        label='exact system' )\n",
    "            pylab.plot( A_col0_sorted[:,0],\n",
    "                        numpy.dot(A_col0_sorted,linear_fit)[:,0],\n",
    "                        label='linear fit' )\n",
    "            pylab.legend()\n",
    "            pylab.show()\n",
    "  \n",
    " if __name__=='__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
