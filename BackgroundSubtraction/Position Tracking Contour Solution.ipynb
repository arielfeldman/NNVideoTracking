{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours, LineModelND, ransac\n",
    "import scipy.spatial as spatial\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#Find homography\n",
    "source_pts = np.array([[100, 90], [475, 70], [425, 370], [75, 470]], dtype = 'float32') #pixels!\n",
    "dst_pts = np.array([[0, 0], [100, 0], [80, 80], [0, 100]], dtype = 'float32') #cm\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(source_pts, dst_pts, cv2.RANSAC, 5.0) #not sure what the 5.0 is really doing seems to work though\n",
    "POINTMOO = np.array([[75,470]],dtype = 'float32')\n",
    "POINTMOO = np.array([POINTMOO])\n",
    "dst_pt = cv2.perspectiveTransform(POINTMOO, homography_matrix)\n",
    "#print(dst_pt[0][0][0])\n",
    "#print(dst_pt[0][0][1])\n",
    "#print(dst_pt)\n",
    "#Locations of objects and distance thresholds (how close does the rat have to be to be near it)\n",
    "familiarObject_center_x = 380\n",
    "familiarObject_center_y = 160\n",
    "realWorld_famObj_center = cv2.perspectiveTransform(np.array([np.array([[familiarObject_center_x,familiarObject_center_y]], dtype='float32')]), homography_matrix)\n",
    "familiarObject_center_x_realWorld = realWorld_famObj_center[0][0][0]\n",
    "familiarObject_center_y_realWorld = realWorld_famObj_center[0][0][1]\n",
    "DistanceThreshold_familiarObject = 22;\n",
    "numFrames_FamiliarObject = 0;\n",
    "\n",
    "novelObject_center_x = 210\n",
    "novelObject_center_y = 320\n",
    "realWorld_novelObj_center = cv2.perspectiveTransform(np.array([np.array([[novelObject_center_x,novelObject_center_y]],dtype='float32')]), homography_matrix)\n",
    "novelObject_center_x_realWorld = realWorld_novelObj_center[0][0][0]\n",
    "novelObject_center_y_realWorld = realWorld_novelObj_center[0][0][1]\n",
    "DistanceThrehshold_NovelObject = 22;\n",
    "numFrames_NovelObject = 0;\n",
    "\n",
    "#setup for background model and foreground tracking\n",
    "if 'fgbg' not in locals():\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "    \n",
    "morph_size = 2\n",
    "shadowValue = 127\n",
    "learnBG = False\n",
    "showShadow = False\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "\n",
    "# # Helper functions to find intersection of line and contours\n",
    "\n",
    "# def intersection(points1, points2, eps):\n",
    "#     tree = spatial.KDTree(points1)\n",
    "#     distances, indices = tree.query(points2, k=1, distance_upper_bound=eps)\n",
    "#     intersection_points = tree.data[indices[np.isfinite(distances)]]\n",
    "#     return intersection_points\n",
    "\n",
    "\n",
    "# def cluster(points, cluster_size):\n",
    "#     dists = dist.pdist(points, metric='sqeuclidean')\n",
    "#     linkage_matrix = hier.linkage(dists, 'average')\n",
    "#     groups = hier.fcluster(linkage_matrix, cluster_size, criterion='distance')\n",
    "#     return np.array([points[cluster].mean(axis=0)\n",
    "#                      for cluster in clusterlists(groups)])\n",
    "\n",
    "\n",
    "# def contour_points(contour, steps=1):\n",
    "#     return np.row_stack([path.interpolated(steps).vertices\n",
    "#                          for linecol in contour.collections\n",
    "#                          for path in linecol.get_paths()])\n",
    "\n",
    "\n",
    "# def clusterlists(T):\n",
    "#     '''\n",
    "#     http://stackoverflow.com/a/2913071/190597 (denis)\n",
    "#     T = [2, 1, 1, 1, 2, 2, 2, 2, 2, 1]\n",
    "#     Returns [[0, 4, 5, 6, 7, 8], [1, 2, 3, 9]]\n",
    "#     '''\n",
    "#     groups = collections.defaultdict(list)\n",
    "#     for i, elt in enumerate(T):\n",
    "#         groups[elt].append(i)\n",
    "#     return sorted(groups.values(), key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Work Happens Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('Round2/Day3/Test-2-cropped.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "        \n",
    "#MOOO\n",
    "        #Contour and line of best fit\n",
    "        _, contours, _ = cv2.findContours(fgmask,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #print(contours[0])\n",
    "        #print(ratContours)\n",
    "        rows, cols = im.shape[:2]\n",
    "        [vx,vy,x,y] = cv2.fitLine(contours[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "        cnt = contours[0]\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        im = cv2.drawContours(im,[box],0,(0,0,255),2)\n",
    "        minr, minc, maxr, maxc = ratBlob.bbox\n",
    "        (c0x, c0y), (c1x, c1y), (c2x, c2y), (c3x, c3y) = cv2.boxPoints((rect))\n",
    "        cv2.drawContours(im, contours, 0,(0,255,0),2)\n",
    "        line = cv2.arrowedLine(im,(c0x, c0y),(c2x, c2y),(255,0,0),2)\n",
    "#         int_pts = []\n",
    "#         for lpt in line:\n",
    "#             for cpt in contours:\n",
    "#                 if lpt == cpt:\n",
    "#                     int_pts.append(lpt)\n",
    "#         if len(int_pts) > 0:\n",
    "#             intpoint1x, intpoint1y = int_pts[0]\n",
    "                    \n",
    "        \n",
    "#         # every intersection point must be within eps of a point on the other\n",
    "#         # contour path\n",
    "#         eps = 1.0\n",
    "\n",
    "#         # cluster together intersection points so that the original points in each flat\n",
    "#         # cluster have a cophenetic_distance < cluster_size\n",
    "#         cluster_size = 100\n",
    "\n",
    "#         xlin = np.linspace(-1, 1, 500)\n",
    "#         X, Y = np.meshgrid(xlin, xlin)\n",
    "#         contour1 = plt.contour(cont, colors='k')\n",
    "#         contour2 = plt.contour(arrow_line, colors='r')\n",
    "\n",
    "#         points1 = contour_points(contour1)\n",
    "#         points2 = contour_points(contour2)\n",
    "\n",
    "#         intersection_points = intersection(points1, points2, eps)\n",
    "#         intersection_points = cluster(intersection_points, cluster_size)\n",
    "#         plt.scatter(intersection_points[:, 0], intersection_points[:, 1], s=20)\n",
    "        \n",
    "\n",
    "        #draw tracking \"dot\"\n",
    "        cv2.circle(im,(int(x0),int(y0)),10,(255,255,255),-11)\n",
    "        cv2.circle(im,(int(x0),int(y0)),11,(0,0,255),1) # draw circle\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "        cv2.circle(im,(int(x0),int(y0)),1,(0,255,0),1) # draw center\n",
    "        #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        # 'dot' location of familiar object\n",
    "        cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        # 'dot' location of novel object\n",
    "        cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "        distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "        distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "        if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "            numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "            cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "        if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "            numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "            cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "            \n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n",
    "timeSpentFamObject = numFrames_FamiliarObject/fps\n",
    "timeSpentNovObject = numFrames_NovelObject/fps\n",
    "\n",
    "timeSpent = ('Familiar', 'Novel')\n",
    "n_groups = len(timeSpent)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.1\n",
    "\n",
    "plt.bar(index, [timeSpentFamObject, timeSpentNovObject], bar_width, color='blue', align='center', alpha=0.6)\n",
    "\n",
    "plt.title(\"Time Spent with Objects\")\n",
    "plt.xticks(index, ('Familiar', 'Novel'))\n",
    "plt.xlabel(\"Object\")\n",
    "plt.ylabel(\"Time (Seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('Round2/Day3/Test-2-cropped.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "                \n",
    "        #generate coordinates of line\n",
    "        minr, minc, maxr, maxc = ratBlob.bbox\n",
    "        width = (maxc - minc) + 1\n",
    "        height = (maxr - minr) + 1\n",
    "        slope = (height / width)\n",
    "        for x in range(0, width):\n",
    "            y = (slope * (x - x0)) + y0\n",
    "        \n",
    "        data = ratBlob.coords\n",
    "        \n",
    "#         rows,cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(cnt, cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx)+y)\n",
    "#         cv2.line(im,(cols-1,righty),(0,lefty),(0,255,0),2)\n",
    "        \n",
    "        #fit line using all data\n",
    "        model = LineModelND()\n",
    "        model.estimate(data)\n",
    "        \n",
    "        #robustly fit line only using inlier data with RANSAC algorithm\n",
    "        model_robust, inliers = ransac(data, LineModelND, min_samples = 2, residual_threshold = 1, max_trials = 1000)\n",
    "        outliers = inliers == False\n",
    "        \n",
    "        #generate coordinates of estimated models\n",
    "        line_x = np.arange(0, width)\n",
    "        line_y = model.predict_y(line_x)\n",
    "        line_y_robust = model_robust.predict_y(line_x)\n",
    "                \n",
    "#         fig, ax = plt.subplots()\n",
    "#         #ax.plot(data[inliers, 0], data[inliers, 1], '.b', alpha = 0.6, label = 'Inlier data')\n",
    "#         #ax.plot(data[outliers, 0], data[outliers, 1], '.r', alpha = 0.6, label = 'Outlier data')\n",
    "#         ax.plot(line_x, line_y, '-k', label = 'Line model from all data')\n",
    "#         #ax.plot(line_x, line_y_robust, '-b', label = 'Robust line model')\n",
    "#         ax.legend (loc = 'lower left')\n",
    "#         plt.show()\n",
    "#MOOO\n",
    "        #Contour and line of best fit\n",
    "#         _, contours, _ = cv2.findContours(fgmask,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         #print(contours[0])\n",
    "#         #print(ratContours)\n",
    "#         rows, cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(contours[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx) + y)\n",
    "#         cv2.drawContours(im, contours, 0,(0,255,0),2)\n",
    "#         cv2.arrowedLine(im,(cols-1,righty),(0,lefty),(255,0,0),2)\n",
    "\n",
    "        #draw tracking \"dot\"\n",
    "        cv2.circle(im,(int(x0),int(y0)),10,(255,255,255),-11)\n",
    "        cv2.circle(im,(int(x0),int(y0)),11,(0,0,255),1) # draw circle\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "        cv2.circle(im,(int(x0),int(y0)),1,(0,255,0),1) # draw center\n",
    "        #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        # 'dot' location of familiar object\n",
    "        cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        # 'dot' location of novel object\n",
    "        cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "        distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "        distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "        if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "            numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "            cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "        if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "            numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "            cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "            \n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n",
    "timeSpentFamObject = numFrames_FamiliarObject/fps\n",
    "timeSpentNovObject = numFrames_NovelObject/fps\n",
    "\n",
    "timeSpent = ('Familiar', 'Novel')\n",
    "n_groups = len(timeSpent)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.1\n",
    "\n",
    "plt.bar(index, [timeSpentFamObject, timeSpentNovObject], bar_width, color='blue', align='center', alpha=0.6)\n",
    "\n",
    "plt.title(\"Time Spent with Objects\")\n",
    "plt.xticks(index, ('Familiar', 'Novel'))\n",
    "plt.xlabel(\"Object\")\n",
    "plt.ylabel(\"Time (Seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours, LineModelND, ransac\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('Round2/Day3/Test-2-cropped.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "                \n",
    "        #generate coordinates of line\n",
    "        minr, minc, maxr, maxc = ratBlob.bbox\n",
    "        width = (maxc - minc) + 1\n",
    "        height = (maxr - minr) + 1\n",
    "        slope = (height / width)\n",
    "        for x in range(0, width):\n",
    "            y = (slope * (x - x0)) + y0\n",
    "        \n",
    "        data = ratBlob.coords\n",
    "        \n",
    "        #fit line using all data\n",
    "        model = LineModelND()\n",
    "        model.estimate(data)\n",
    "        \n",
    "        #robustly fit line only using inlier data with RANSAC algorithm\n",
    "        #model_robust, inliers = ransac(data, LineModelND, min_samples = 2, residual_threshold = 1, max_trials = 1000)\n",
    "        #outliers = inliers == False\n",
    "        \n",
    "        #generate coordinates of estimated models\n",
    "        line_x = np.arange(0, width)\n",
    "        line_y = model.predict_y(line_x)\n",
    "        #line_y_robust = model_robust.predict_y(line_x)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        #ax.plot(data[inliers, 0], data[inliers, 1], '.b', alpha = 0.6, label = 'Inlier data')\n",
    "        #ax.plot(data[outliers, 0], data[outliers, 1], '.r', alpha = 0.6, label = 'Outlier data')\n",
    "        ax.plot(line_x, line_y, '-k', label = 'Line model from all data')\n",
    "        #ax.plot(line_x, line_y_robust, '-b', label = 'Robust line model')\n",
    "        ax.legend (loc = 'lower left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage.measure import LineModelND, ransac\n",
    "\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "# generate coordinates of line\n",
    "x = np.arange(-200, 200)\n",
    "y = 0.2 * x + 20\n",
    "data = np.column_stack([x, y])\n",
    "\n",
    "# add faulty data\n",
    "faulty = np.array(30 * [(180., -100)])\n",
    "faulty += 5 * np.random.normal(size=faulty.shape)\n",
    "data[:faulty.shape[0]] = faulty\n",
    "\n",
    "# add gaussian noise to coordinates\n",
    "noise = np.random.normal(size=data.shape)\n",
    "data += 0.5 * noise\n",
    "data[::2] += 5 * noise[::2]\n",
    "data[::4] += 20 * noise[::4]\n",
    "\n",
    "# fit line using all data\n",
    "model = LineModelND()\n",
    "model.estimate(data)\n",
    "\n",
    "# robustly fit line only using inlier data with RANSAC algorithm\n",
    "model_robust, inliers = ransac(data, LineModelND, min_samples=2,\n",
    "                               residual_threshold=1, max_trials=1000)\n",
    "outliers = inliers == False\n",
    "\n",
    "# generate coordinates of estimated models\n",
    "line_x = np.arange(-250, 250)\n",
    "line_y = model.predict_y(line_x)\n",
    "line_y_robust = model_robust.predict_y(line_x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[inliers, 0], data[inliers, 1], '.b', alpha=0.6,\n",
    "        label='Inlier data')\n",
    "ax.plot(data[outliers, 0], data[outliers, 1], '.r', alpha=0.6,\n",
    "        label='Outlier data')\n",
    "ax.plot(line_x, line_y, '-k', label='Line model from all data')\n",
    "ax.plot(line_x, line_y_robust, '-b', label='Robust line model')\n",
    "ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
