{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours, LineModelND, ransac\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#Find homography\n",
    "source_pts = np.array([[100, 90], [475, 70], [425, 370], [75, 470]], dtype = 'float32') #pixels!\n",
    "dst_pts = np.array([[0, 0], [100, 0], [80, 80], [0, 100]], dtype = 'float32') #cm\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(source_pts, dst_pts, cv2.RANSAC, 5.0) #not sure what the 5.0 is really doing seems to work though\n",
    "POINTMOO = np.array([[75,470]],dtype = 'float32')\n",
    "POINTMOO = np.array([POINTMOO])\n",
    "dst_pt = cv2.perspectiveTransform(POINTMOO, homography_matrix)\n",
    "#print(dst_pt[0][0][0])\n",
    "#print(dst_pt[0][0][1])\n",
    "#print(dst_pt)\n",
    "#Locations of objects and distance thresholds (how close does the rat have to be to be near it)\n",
    "familiarObject_center_x = 380\n",
    "familiarObject_center_y = 160\n",
    "realWorld_famObj_center = cv2.perspectiveTransform(np.array([np.array([[familiarObject_center_x,familiarObject_center_y]], dtype='float32')]), homography_matrix)\n",
    "familiarObject_center_x_realWorld = realWorld_famObj_center[0][0][0]\n",
    "familiarObject_center_y_realWorld = realWorld_famObj_center[0][0][1]\n",
    "DistanceThreshold_familiarObject = 22;\n",
    "numFrames_FamiliarObject = 0;\n",
    "\n",
    "novelObject_center_x = 210\n",
    "novelObject_center_y = 320\n",
    "realWorld_novelObj_center = cv2.perspectiveTransform(np.array([np.array([[novelObject_center_x,novelObject_center_y]],dtype='float32')]), homography_matrix)\n",
    "novelObject_center_x_realWorld = realWorld_novelObj_center[0][0][0]\n",
    "novelObject_center_y_realWorld = realWorld_novelObj_center[0][0][1]\n",
    "DistanceThrehshold_NovelObject = 22;\n",
    "numFrames_NovelObject = 0;\n",
    "\n",
    "#setup for background model and foreground tracking\n",
    "if 'fgbg' not in locals():\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "    \n",
    "morph_size = 2\n",
    "shadowValue = 127\n",
    "learnBG = False\n",
    "showShadow = False\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Work Happens Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video file length is 697.2333333333333 seconds\n",
      "input video file has a framerate of 30.0 fps\n",
      "shadows ON\n",
      "shadows OFF\n",
      "background learning ON\n",
      "background learning OFF\n",
      "Total amount of time spent with objects: 33.333333333333336 seconds\n",
      "Percentage of time spent with objects that was spent with the novel object: 91.89999999999999%\n",
      "exited gracefully\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEZCAYAAACU3p4jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+P9ZGylnZYx5lAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd805f6e7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('Round2/Day3/Test-2-cropped.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "        \n",
    "#MOOO\n",
    "        #Contour and line of best fit\n",
    "#         _, contours, _ = cv2.findContours(fgmask,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         #print(contours[0])\n",
    "#         #print(ratContours)\n",
    "#         rows, cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(contours[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx) + y)\n",
    "#         cv2.drawContours(im, contours, 0,(0,255,0),2)\n",
    "#         cv2.arrowedLine(im,(cols-1,righty),(0,lefty),(255,0,0),2)\n",
    "\n",
    "        #draw tracking \"dot\"\n",
    "        cv2.circle(im,(int(x0),int(y0)),10,(255,255,255),-11)\n",
    "        cv2.circle(im,(int(x0),int(y0)),11,(0,0,255),1) # draw circle\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "        cv2.circle(im,(int(x0),int(y0)),1,(0,255,0),1) # draw center\n",
    "        #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        # 'dot' location of familiar object\n",
    "        cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        # 'dot' location of novel object\n",
    "        cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "        distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "        distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "        if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "            numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "            cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "        if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "            numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "            cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "            \n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n",
    "timeSpentFamObject = numFrames_FamiliarObject/fps\n",
    "timeSpentNovObject = numFrames_NovelObject/fps\n",
    "\n",
    "timeSpent = ('Familiar', 'Novel')\n",
    "n_groups = len(timeSpent)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.1\n",
    "\n",
    "plt.bar(index, [timeSpentFamObject, timeSpentNovObject], bar_width, color='blue', align='center', alpha=0.6)\n",
    "\n",
    "plt.title(\"Time Spent with Objects\")\n",
    "plt.xticks(index, ('Familiar', 'Novel'))\n",
    "plt.xlabel(\"Object\")\n",
    "plt.ylabel(\"Time (Seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video file length is 697.2333333333333 seconds\n",
      "input video file has a framerate of 30.0 fps\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-57e00157a1a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m#robustly fit line only using inlier data with RANSAC algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mmodel_robust\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mransac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLineModelND\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0moutliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minliers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kemerelab/anaconda3/lib/python3.5/site-packages/skimage/measure/fit.py\u001b[0m in \u001b[0;36mransac\u001b[1;34m(data, model_class, min_samples, residual_threshold, is_data_valid, is_model_valid, max_trials, stop_sample_num, stop_residuals_sum, stop_probability)\u001b[0m\n\u001b[0;32m    883\u001b[0m         \u001b[0msample_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# backwards compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kemerelab/anaconda3/lib/python3.5/site-packages/skimage/measure/fit.py\u001b[0m in \u001b[0;36mestimate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[0mu\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# over-determined\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''"
     ]
    }
   ],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('Round2/Day3/Test-2-cropped.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "                \n",
    "        #generate coordinates of line\n",
    "        minr, minc, maxr, maxc = ratBlob.bbox\n",
    "        width = (maxc - minc) + 1\n",
    "        height = (maxr - minr) + 1\n",
    "        slope = (height / width)\n",
    "        for x in range(0, width):\n",
    "            y = (slope * (x - x0)) + y0\n",
    "        \n",
    "        data = ratBlob.coords\n",
    "        \n",
    "#         rows,cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(cnt, cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx)+y)\n",
    "#         cv2.line(im,(cols-1,righty),(0,lefty),(0,255,0),2)\n",
    "        \n",
    "        #fit line using all data\n",
    "        model = LineModelND()\n",
    "        model.estimate(data)\n",
    "        \n",
    "        #robustly fit line only using inlier data with RANSAC algorithm\n",
    "        model_robust, inliers = ransac(data, LineModelND, min_samples = 2, residual_threshold = 1, max_trials = 1000)\n",
    "        outliers = inliers == False\n",
    "        \n",
    "        #generate coordinates of estimated models\n",
    "        line_x = np.arange(0, width)\n",
    "        line_y = model.predict_y(line_x)\n",
    "        line_y_robust = model_robust.predict_y(line_x)\n",
    "                \n",
    "#         fig, ax = plt.subplots()\n",
    "#         #ax.plot(data[inliers, 0], data[inliers, 1], '.b', alpha = 0.6, label = 'Inlier data')\n",
    "#         #ax.plot(data[outliers, 0], data[outliers, 1], '.r', alpha = 0.6, label = 'Outlier data')\n",
    "#         ax.plot(line_x, line_y, '-k', label = 'Line model from all data')\n",
    "#         #ax.plot(line_x, line_y_robust, '-b', label = 'Robust line model')\n",
    "#         ax.legend (loc = 'lower left')\n",
    "#         plt.show()\n",
    "#MOOO\n",
    "        #Contour and line of best fit\n",
    "#         _, contours, _ = cv2.findContours(fgmask,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         #print(contours[0])\n",
    "#         #print(ratContours)\n",
    "#         rows, cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(contours[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx) + y)\n",
    "#         cv2.drawContours(im, contours, 0,(0,255,0),2)\n",
    "#         cv2.arrowedLine(im,(cols-1,righty),(0,lefty),(255,0,0),2)\n",
    "\n",
    "        #draw tracking \"dot\"\n",
    "        cv2.circle(im,(int(x0),int(y0)),10,(255,255,255),-11)\n",
    "        cv2.circle(im,(int(x0),int(y0)),11,(0,0,255),1) # draw circle\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "        cv2.circle(im,(int(x0),int(y0)),1,(0,255,0),1) # draw center\n",
    "        #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        # 'dot' location of familiar object\n",
    "        cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        # 'dot' location of novel object\n",
    "        cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "        distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "        distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "        if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "            numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "            cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "        if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "            numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "            cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "            \n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n",
    "timeSpentFamObject = numFrames_FamiliarObject/fps\n",
    "timeSpentNovObject = numFrames_NovelObject/fps\n",
    "\n",
    "timeSpent = ('Familiar', 'Novel')\n",
    "n_groups = len(timeSpent)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.1\n",
    "\n",
    "plt.bar(index, [timeSpentFamObject, timeSpentNovObject], bar_width, color='blue', align='center', alpha=0.6)\n",
    "\n",
    "plt.title(\"Time Spent with Objects\")\n",
    "plt.xticks(index, ('Familiar', 'Novel'))\n",
    "plt.xlabel(\"Object\")\n",
    "plt.ylabel(\"Time (Seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours, LineModelND, ransac\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader('Round2/Day3/Test-2-cropped.mkv')\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "        #ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "        #ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "        #cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "        #cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "                \n",
    "        #generate coordinates of line\n",
    "        minr, minc, maxr, maxc = ratBlob.bbox\n",
    "        width = (maxc - minc) + 1\n",
    "        height = (maxr - minr) + 1\n",
    "        slope = (height / width)\n",
    "        for x in range(0, width):\n",
    "            y = (slope * (x - x0)) + y0\n",
    "        \n",
    "        data = ratBlob.coords\n",
    "        \n",
    "        #fit line using all data\n",
    "        model = LineModelND()\n",
    "        model.estimate(data)\n",
    "        \n",
    "        #robustly fit line only using inlier data with RANSAC algorithm\n",
    "        #model_robust, inliers = ransac(data, LineModelND, min_samples = 2, residual_threshold = 1, max_trials = 1000)\n",
    "        #outliers = inliers == False\n",
    "        \n",
    "        #generate coordinates of estimated models\n",
    "        line_x = np.arange(0, width)\n",
    "        line_y = model.predict_y(line_x)\n",
    "        #line_y_robust = model_robust.predict_y(line_x)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        #ax.plot(data[inliers, 0], data[inliers, 1], '.b', alpha = 0.6, label = 'Inlier data')\n",
    "        #ax.plot(data[outliers, 0], data[outliers, 1], '.r', alpha = 0.6, label = 'Outlier data')\n",
    "        ax.plot(line_x, line_y, '-k', label = 'Line model from all data')\n",
    "        #ax.plot(line_x, line_y_robust, '-b', label = 'Robust line model')\n",
    "        ax.legend (loc = 'lower left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage.measure import LineModelND, ransac\n",
    "\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "# generate coordinates of line\n",
    "x = np.arange(-200, 200)\n",
    "y = 0.2 * x + 20\n",
    "data = np.column_stack([x, y])\n",
    "\n",
    "# add faulty data\n",
    "faulty = np.array(30 * [(180., -100)])\n",
    "faulty += 5 * np.random.normal(size=faulty.shape)\n",
    "data[:faulty.shape[0]] = faulty\n",
    "\n",
    "# add gaussian noise to coordinates\n",
    "noise = np.random.normal(size=data.shape)\n",
    "data += 0.5 * noise\n",
    "data[::2] += 5 * noise[::2]\n",
    "data[::4] += 20 * noise[::4]\n",
    "\n",
    "# fit line using all data\n",
    "model = LineModelND()\n",
    "model.estimate(data)\n",
    "\n",
    "# robustly fit line only using inlier data with RANSAC algorithm\n",
    "model_robust, inliers = ransac(data, LineModelND, min_samples=2,\n",
    "                               residual_threshold=1, max_trials=1000)\n",
    "outliers = inliers == False\n",
    "\n",
    "# generate coordinates of estimated models\n",
    "line_x = np.arange(-250, 250)\n",
    "line_y = model.predict_y(line_x)\n",
    "line_y_robust = model_robust.predict_y(line_x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[inliers, 0], data[inliers, 1], '.b', alpha=0.6,\n",
    "        label='Inlier data')\n",
    "ax.plot(data[outliers, 0], data[outliers, 1], '.r', alpha=0.6,\n",
    "        label='Outlier data')\n",
    "ax.plot(line_x, line_y, '-k', label='Line model from all data')\n",
    "ax.plot(line_x, line_y_robust, '-b', label='Robust line model')\n",
    "ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
