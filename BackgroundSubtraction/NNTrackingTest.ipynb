{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "from skimage.draw import line, set_color\n",
    "import imageio\n",
    "import cv2\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "# from Tkinter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homography for Novel Objects and Animal Speed Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find homography\n",
    "source_pts = np.array([[100, 90], [475, 70], [425, 370], [75, 470]], dtype = 'float32') #pixels!\n",
    "dst_pts = np.array([[0, 0], [100, 0], [80, 80], [0, 100]], dtype = 'float32') #cm\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(source_pts, dst_pts, cv2.RANSAC, 5.0) #not sure what the 5.0 is really doing seems to work though\n",
    "POINTMOO = np.array([[75,470]],dtype = 'float32')\n",
    "POINTMOO = np.array([POINTMOO])\n",
    "dst_pt = cv2.perspectiveTransform(POINTMOO, homography_matrix)\n",
    "#print(dst_pt[0][0][0])\n",
    "#print(dst_pt[0][0][1])\n",
    "#print(dst_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locations of objects and distance thresholds (how close does the rat have to be to be near it)\n",
    "familiarObject_center_x = 380\n",
    "familiarObject_center_y = 160\n",
    "realWorld_famObj_center = cv2.perspectiveTransform(np.array([np.array([[familiarObject_center_x,familiarObject_center_y]], dtype='float32')]), homography_matrix)\n",
    "familiarObject_center_x_realWorld = realWorld_famObj_center[0][0][0]\n",
    "familiarObject_center_y_realWorld = realWorld_famObj_center[0][0][1]\n",
    "DistanceThreshold_familiarObject = 22; #cm\n",
    "numFrames_FamiliarObject = 0;\n",
    "\n",
    "novelObject_center_x = 210\n",
    "novelObject_center_y = 320\n",
    "realWorld_novelObj_center = cv2.perspectiveTransform(np.array([np.array([[novelObject_center_x,novelObject_center_y]],dtype='float32')]), homography_matrix)\n",
    "novelObject_center_x_realWorld = realWorld_novelObj_center[0][0][0]\n",
    "novelObject_center_y_realWorld = realWorld_novelObj_center[0][0][1]\n",
    "DistanceThrehshold_NovelObject = 22; #cm\n",
    "numFrames_NovelObject = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "53592it [1:02:13, 14.35it/s]"
     ]
    }
   ],
   "source": [
    "DistanceThrehshold_NovelObject = 15 #cm\n",
    "DistanceThreshold_familiarObject = 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chop off first X seconds\n",
    "import subprocess\n",
    "seconds = \"40\"\n",
    "# subprocess.call(['ffmpeg','-i', 'Round2/Day3/Test-2-cropped.mkv', '-ss', seconds, 'Round2/Day3/Test-2-cropped-1.mkv'])\n",
    "subprocess.call(['ffmpeg','-i', '/home/kemerelab/Downloads/5-3-18-1-stim1_predicted_171838.mp4', '-ss', seconds, '/home/kemerelab/Downloads/5-3-18-1-stim1_predicted_171838-cropped.mp4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Tracking File Name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/kemerelab/Downloads/4_26_18-converted.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Work Happens Below\n",
    "## Initialize stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup for background model and foreground tracking\n",
    "if 'fgbg' not in locals():\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "    \n",
    "morph_size = 2\n",
    "shadowValue = 127\n",
    "learnBG = False\n",
    "showShadow = False\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just use this to train the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-danger\">\n",
    "<b> ARIEL:</b> Remove the centroid tracking from this and displaying the fgmask and saving the video, please. Thank you! I'd do it myself but it's more fun to write things in red bold letters. This will make things a little faster but honestly this entire thing needs to be faster and parallelized as much as possible (discuss sometime).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader(filename)\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "# cv2.morph_open\n",
    "centers=[]\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "    \n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        #print(ratBlob.perimeter)\n",
    "#         ratContours = find_contours(fgmask,0.8)\n",
    "        #print(ratContours)\n",
    "#         ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "#         cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "#         cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        y0, x0 = ratBlob.centroid\n",
    "        centers.append([x0,y0])\n",
    "#MOOO\n",
    "        #Contour and line of best fit\n",
    "#         _, contours, _ = cv2.findContours(fgmask,cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         #print(contours[0])\n",
    "#         #print(ratContours)\n",
    "#         rows, cols = im.shape[:2]\n",
    "#         [vx,vy,x,y] = cv2.fitLine(contours[0], cv2.DIST_L2,0,0.01,0.01)\n",
    "#         lefty = int((-x*vy/vx) + y)\n",
    "#         righty = int(((cols-x)*vy/vx) + y)\n",
    "#         cv2.drawContours(im, contours, 0,(0,255,0),2)\n",
    "#         cv2.arrowedLine(im,(cols-1,righty),(0,lefty),(255,0,0),2)\n",
    "\n",
    "        #draw tracking \"dot\"\n",
    "        cv2.circle(im,(int(x0),int(y0)),10,(255,255,255),-11)\n",
    "        cv2.circle(im,(int(x0),int(y0)),11,(0,0,255),1) # draw circle\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "        cv2.ellipse(im, (int(x0),int(y0)), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "        cv2.circle(im,(int(x0),int(y0)),1,(0,255,0),1) # draw center\n",
    "        #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bifurcations\n",
    "<br>\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>ARIEL:</b> Remove the background model display from this one please! Thank you! Once again, I could do it myself but I'm having fun writing in red letters and same as above it's irrelevant in the long run but will be faster in the short-term for you\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader(filename)\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "refPt = []\n",
    "\n",
    "# def click(event, x, y, flags, param):\n",
    "#     # grab references to the global variables\n",
    "#     global refPt\n",
    "    \n",
    "#     # if the left mouse button was clicked, record the starting\n",
    "#     # (x, y) coordinates and indicate that cropping is being\n",
    "#     # performed\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         refPt = [(x, y)]\n",
    "#         posx = refPt[0]\n",
    "#         posy = refPt[1]\n",
    "#         return posx, posy\n",
    "\n",
    "# click(cv2.EVENT_LBUTTONDOWN)\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, m, n):\n",
    "        self.coordinates = np.zeros((m, n))\n",
    "        self.click = False\n",
    "\n",
    "    def select_coordinates(self, event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            #Set coordinates to mouse position\n",
    "            self.coordinates[i, :] = [x, y]\n",
    "            self.clickcoords = [x,y]\n",
    "            print (self.clickcoords[0], self.clickcoords[1])\n",
    "            self.click = True\n",
    "position = Position(reader.get_length(), 2)\n",
    "cv2.namedWindow('im', flags=cv2.WINDOW_AUTOSIZE)\n",
    "cv2.setMouseCallback('im', position.select_coordinates)\n",
    "\n",
    "\n",
    "centers1 = {}\n",
    "centers2 = {}\n",
    "\n",
    "def dist_pts(y,x,yy,xx):\n",
    "#     ht = (int(yy)-int(y))**2\n",
    "#     wdth = (int(xx)-int(x))**2\n",
    "#     if ht == 0:\n",
    "#         dist = int(xx) - int(x)\n",
    "#     elif wdth == 0:\n",
    "#         dist = int(yy) - int(y)\n",
    "#     else:\n",
    "#         dist = math.sqrt(ht/wdth)\n",
    "    dist = math.hypot(xx - x, yy - y)\n",
    "    return dist\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "        \n",
    "        # Find largest object in foreground\n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        # Find center coordinates of largest foreground object\n",
    "        y0, x0 = ratBlob.centroid\n",
    "        cv2.circle(im,(int(x0), int(y0)),10,(255,0,0),-11)\n",
    "        # Find angle between x axis and major axis of an ellipse around largest foreground object\n",
    "        orient_ratBlob = ratBlob.orientation\n",
    "        \n",
    "        # Find coordinates of endpoints of major axis\n",
    "#         x1 = x0 + math.cos(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "#         y1 = y0 - math.sin(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "        x2 = x0 - math.sin(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        y2 = y0 - math.cos(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        x3 = x0 + math.sin(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        y3 = y0 + math.cos(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        \n",
    "        rr1, cc1 = line(int(y0), int(x0), int(y2), int(x2))\n",
    "        rr2, cc2 = line(int(y0), int(x0), int(y3), int(x3))\n",
    "        rr3, cc3 = line(int(y0)+1, int(x0), int(y2)+1, int(x2))\n",
    "        rr4, cc4 = line(int(y0)+1, int(x0), int(y3)+1, int(x3))\n",
    "        \n",
    "        set_color(fgmask, (rr1, cc1), (0), 1)\n",
    "        set_color(fgmask, (rr2, cc2), (0), 1)\n",
    "        set_color(fgmask, (rr3, cc3), (0), 1)\n",
    "        set_color(fgmask, (rr4, cc4), (0), 1)\n",
    "\n",
    "        \n",
    "        label_halves = label(fgmask)\n",
    "        regions = regionprops(label_halves)\n",
    "        \n",
    "#         print (len(regions))\n",
    "        \n",
    "        if len(regions) > 1:\n",
    "            regions_area1 = []\n",
    "            \n",
    "            rathalf1 = regions[0]\n",
    "            \n",
    "            y01, x01 = rathalf1.centroid\n",
    "            #calculating intersection points of bifurcating line with rat outline\n",
    "            #             x11 = x01 - math.cos(orient_ratBlob) * 0.5 * rathalf1.major_axis_length\n",
    "            #             y11 = y01 + math.sin(orient_ratBlob) * 0.5 * rathalf1.major_axis_length\n",
    "            x21 = x01 - math.sin(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            y21 = y01 - math.cos(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            x31 = x01 + math.sin(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            y31 = y01 + math.cos(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            \n",
    "            #drawing two lines next to each other to make a thicker line\n",
    "            rrh11, cch11 = line(int(y01), int(x01), int(y21), int(x21))\n",
    "            rrh12, cch12 = line(int(y01), int(x01), int(y31), int(x31))\n",
    "            rrh13, cch13 = line(int(y01)+1, int(x01), int(y21)+1, int(x21))\n",
    "            rrh14, cch14 = line(int(y01)+1, int(x01), int(y31)+1, int(x31))\n",
    "            \n",
    "            #set color of lines to opaque black\n",
    "            set_color(fgmask, (rrh11, cch11), (0), 1)\n",
    "            set_color(fgmask, (rrh12, cch12), (0), 1)\n",
    "            set_color(fgmask, (rrh13, cch13), (0), 1)\n",
    "            set_color(fgmask, (rrh14, cch14), (0), 1)\n",
    "            \n",
    "            # label foreground again into two quarters and a half\n",
    "            label_quarters1 = label(fgmask)\n",
    "            regions1 = regionprops(label_quarters1)\n",
    "#             for props1 in regions1:\n",
    "#                 if props1 not in regions:\n",
    "#                     regions_area1.append(props1)\n",
    "\n",
    "            for reg in regions:\n",
    "                if reg in regions1:\n",
    "                    regions1.remove(reg)\n",
    "                \n",
    "            rathalf2 = regions[1]\n",
    "#             print (rathalf2)\n",
    "#             print (len(regions_area1))\n",
    "            \n",
    "            ratquart1 = regions1[0]\n",
    "            ratquart2 = regions1[1]            \n",
    "            rqy1, rqx1 = ratquart1.centroid\n",
    "            rqy2, rqx2 = ratquart2.centroid \n",
    "            \n",
    "            if dist_pts(rqx1, rqy1, x0, y0) > dist_pts(rqx2, rqy2, x0, y0):\n",
    "                hx1 = rqx1\n",
    "                hy1 = rqy1\n",
    "                cv2.circle(im,(int(hx1), int(hy1)),10,(255,255,255),-11)\n",
    "            else:\n",
    "                hx1 = rqx2\n",
    "                hy1 = rqy2\n",
    "                cv2.circle(im,(int(hx1), int(hy1)),10,(255,255,255),-11)\n",
    "\n",
    "           \n",
    "            y02, x02 = rathalf2.centroid\n",
    "#             x12 = x02 - math.cos(orient_ratBlob) * 0.5 * rathalf2.major_axis_length\n",
    "#             y12 = y02 + math.sin(orient_ratBlob) * 0.5 * rathalf2.major_axis_length\n",
    "            x22 = x02 - math.sin(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            y22 = y02 - math.cos(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            x32 = x02 + math.sin(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            y32 = y02 + math.cos(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            \n",
    "            rrh21, cch21 = line(int(y02), int(x02), int(y22), int(x22))\n",
    "            rrh22, cch22 = line(int(y02), int(x02), int(y32), int(x32))\n",
    "            rrh23, cch23 = line(int(y02)+1, int(x02), int(y22)+1, int(x22))\n",
    "            rrh24, cch24 = line(int(y02)+1, int(x02), int(y32)+1, int(x32))\n",
    "            \n",
    "            set_color(fgmask, (rrh21, cch21), (0), 1)\n",
    "            set_color(fgmask, (rrh22, cch22), (0), 1)\n",
    "            set_color(fgmask, (rrh23, cch23), (0), 1)\n",
    "            set_color(fgmask, (rrh24, cch24), (0), 1)\n",
    "            \n",
    "            label_quarters2 = label(fgmask)\n",
    "            regions2 = regionprops(label_quarters2)            \n",
    "            \n",
    "            for reg in regions1:\n",
    "                if reg in regions2:\n",
    "                    regions2.remove(reg)\n",
    "#             print (len(regions2))\n",
    "            #             print(len(regions2))\n",
    "            ratquart3 = regions2[0]\n",
    "            ratquart4 = regions2[1]\n",
    "            rqy3, rqx3 = ratquart3.centroid\n",
    "            rqy4, rqx4 = ratquart4.centroid\n",
    "            \n",
    "            if dist_pts(rqx3, rqy3, x0, y0) > dist_pts(rqx4, rqy4, x0, y0):\n",
    "                hx2 = rqx3\n",
    "                hy2 = rqy3\n",
    "                cv2.circle(im,(int(hx2), int(hy2)),10,(0,0,255),-11)\n",
    "\n",
    "            else:\n",
    "                hx2 = rqx4\n",
    "                hy2 = rqy4\n",
    "                cv2.circle(im,(int(hx2), int(hy2)),10,(0,0,255),-11)\n",
    "#                 cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),10,(255,255,255),-11)\n",
    "            \n",
    "            if dist_pts(hx1, hy1, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "                > dist_pts(hx2, hy2, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]):\n",
    "                position.coordinates[i, : ] = [hx2, hy2]\n",
    "            else:\n",
    "                position.coordinates[i, : ] = [hx1, hy1]\n",
    "            \n",
    "            \n",
    "#             dist = lambda pt1, pt2: math.hypot(pt2[0]-pt1[0], pt2[1]-pt1[1])\n",
    "#             dist(centers,centers)\n",
    "#             def ptdiff(lst):\n",
    "#                 return lambda p1,p2: (math.hypot(p1[0]-p2[0], p1[1]-p2[1]))\n",
    "#             diff = ptdiff(centers)\n",
    "#             print (diff)\n",
    "            \n",
    "#             diffcent = {}\n",
    "#             diff = {}\n",
    "#             for cent1 in centers1:\n",
    "#                 for cent2 in centers2:\n",
    "#                     dist = math.hypot(centers1[cent1][0]-centers2[cent2][0], centers1[cent1][1] - centers2[cent2][1])\n",
    "#                     diffcent[cent2] = dist\n",
    "#                 diff[cent1] = max(diffcent)\n",
    "#             furthest_quarters = max(diff)\n",
    "#             print (furthest_quarters)\n",
    "            if position.click:\n",
    "                cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),10,(255,255,255),-11)\n",
    "                cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),11,(0,0,255),1) # draw circle\n",
    "                cv2.ellipse(im, (int(position.clickcoords[0]),int(position.clickcoords[1])), (10,10), 0, 0, 90,(0,255,255),-1 )\n",
    "                cv2.ellipse(im, (int(position.clickcoords[0]),int(position.clickcoords[1])), (10,10), 0, 180, 270,(0,255,255),-1 )\n",
    "                cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),1,(0,255,0),1) # draw center\n",
    "                print (\"hi I'm iin here\")\n",
    "                cv2.imshow('imtracker',im)\n",
    "    #             time.sleep(10)\n",
    "                position.click = False\n",
    "            else:\n",
    "                #draw tracking \"dot\"\n",
    "                cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),10,(255,255,255),-11)\n",
    "                cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),11,(0,0,255),1) # draw circle\n",
    "                cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "                cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "                cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),1,(0,255,0),1) # draw center\n",
    "    #         #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))     \n",
    "\n",
    "\n",
    "        \n",
    "#         #draw tracking \"dot\"\n",
    "#         cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),10,(255,255,255),-11)\n",
    "#         cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),11,(0,0,255),1) # draw circle\n",
    "#         cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "#         cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "#         cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),1,(0,255,0),1) # draw center\n",
    "# #         #cv2.putText(OriImage,pid,(int(cx)+10,int(cy)-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(255,180,180))\n",
    "        \n",
    "        # 'dot' location of familiar object\n",
    "        cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        # 'dot' location of novel object\n",
    "        cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "        \n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[x0,y0]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "        \n",
    "        distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "        distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "        if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "            numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "            cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "        if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "            numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "            cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "            \n",
    "        \n",
    "    cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('im',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n",
    "timeSpentFamObject = numFrames_FamiliarObject/fps\n",
    "timeSpentNovObject = numFrames_NovelObject/fps\n",
    "\n",
    "timeSpent = ('Familiar', 'Novel')\n",
    "n_groups = len(timeSpent)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.1\n",
    "\n",
    "plt.bar(index, [timeSpentFamObject, timeSpentNovObject], bar_width, color='blue', align='center', alpha=0.6)\n",
    "\n",
    "plt.title(\"Time Spent with Objects\")\n",
    "plt.xticks(index, ('Familiar', 'Novel'))\n",
    "plt.xlabel(\"Object\")\n",
    "plt.ylabel(\"Time (Seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications - SD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store previous location and maintain location if more blobs pop up\n",
    "<br>\n",
    "<div class=\"alert alert-danger\">\n",
    "This is a quick solution to have a stableish demo for lab meeting which isn't robust and won't/doesn't work well\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader(filename)\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "topleft = []\n",
    "bottomright = []\n",
    "\n",
    "refPt = []\n",
    "\n",
    "# def click(event, x, y, flags, param):\n",
    "#     # gra\n",
    "# b references to the global variables\n",
    "#     global refPt\n",
    "    \n",
    "#     # if the left mouse button was clicked, record the starting\n",
    "#     # (x, y) coordinates and indicate that cropping is being\n",
    "#     # performed\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         refPt = [(x, y)]\n",
    "#         posx = refPt[0]\n",
    "#         posy = refPt[1]\n",
    "#         return posx, posy\n",
    "\n",
    "# click(cv2.EVENT_LBUTTONDOWN)\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, m, n):\n",
    "        self.coordinates = np.zeros((m, n))\n",
    "        self.click = False\n",
    "\n",
    "    def select_coordinates(self, event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            #Set coordinates to mouse position\n",
    "            self.coordinates[i, :] = [x, y]\n",
    "            self.clickcoords = [x,y]\n",
    "            print (self.clickcoords[0], self.clickcoords[1])\n",
    "            self.click = True\n",
    "position = Position(reader.get_length(), 2)\n",
    "cv2.namedWindow('im', flags=cv2.WINDOW_AUTOSIZE)\n",
    "cv2.setMouseCallback('im', position.select_coordinates)\n",
    "\n",
    "\n",
    "centers1 = {}\n",
    "centers2 = {}\n",
    "\n",
    "def dist_pts(y,x,yy,xx):\n",
    "#     ht = (int(yy)-int(y))**2\n",
    "#     wdth = (int(xx)-int(x))**2\n",
    "#     if ht == 0:\n",
    "#         dist = int(xx) - int(x)\n",
    "#     elif wdth == 0:\n",
    "#         dist = int(yy) - int(y)\n",
    "#     else:\n",
    "#         dist = math.sqrt(ht/wdth)\n",
    "    dist = math.hypot(xx - x, yy - y)\n",
    "    return dist\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "        \n",
    "        # Find largest object in foreground\n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        ybox2, xbox2, ybox1, xbox1 = ratBlob.bbox\n",
    "        im2 = cv2.rectangle(im, (xbox1, ybox1), (xbox2, ybox2), (255,255,255))\n",
    "        im2 = cv2.circle(im, (xbox1, ybox1), 2, (255,0,0))\n",
    "        topleft.append(tuple([xbox1,ybox1]))\n",
    "        im2 = cv2.circle(im, (xbox2, ybox2), 2, (0,0,255))\n",
    "        bottomright.append(tuple([xbox2, ybox2]))\n",
    "\n",
    "#         ratContours = find_contours(fgmask,0.8)\n",
    "#         print(np.asarray(ratContours).shape)\n",
    "# #         print(np.asarray(ratContours))\n",
    "#         ratContours = np.asarray(ratContours).reshape(-1,1,2).astype(np.int32)\n",
    "        #print(ratContours)\n",
    "#         cv2.drawContours(im, ratContours,0,(0,255,0),2)\n",
    "#         cv2.putText(im, str(ratContours[0][0]), (30,30), cv2.FONT_HERSHEY_PLAIN,2,255)\n",
    "        \n",
    "        # Find center coordinates of largest foreground object\n",
    "        y0, x0 = ratBlob.centroid\n",
    "#         cv2.circle(im,(int(x0), int(y0)),10,(255,0,0),-11)\n",
    "        # Find angle between x axis and major axis of an ellipse around largest foreground object\n",
    "        orient_ratBlob = ratBlob.orientation\n",
    "                \n",
    "        # Find coordinates of endpoints of major axis\n",
    "#         x1 = x0 + math.cos(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "#         y1 = y0 - math.sin(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "        x1 = x0 + math.cos(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "        y1 = y0 - math.sin(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "        x2 = x0 - math.sin(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        y2 = y0 - math.cos(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        x3 = x0 + math.sin(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        y3 = y0 + math.cos(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "\n",
    "        rr1, cc1 = line(int(y0), int(x0), int(y2), int(x2))\n",
    "        rr2, cc2 = line(int(y0), int(x0), int(y3), int(x3))\n",
    "        rr3, cc3 = line(int(y0)+1, int(x0), int(y2)+1, int(x2))\n",
    "        rr4, cc4 = line(int(y0)+1, int(x0), int(y3)+1, int(x3))\n",
    "\n",
    "        set_color(ratOnlyImg, (rr1, cc1), (0), 1)\n",
    "        set_color(ratOnlyImg, (rr2, cc2), (0), 1)\n",
    "        set_color(ratOnlyImg, (rr3, cc3), (0), 1)\n",
    "        set_color(ratOnlyImg, (rr4, cc4), (0), 1)\n",
    "\n",
    "\n",
    "        label_halves = label(ratOnlyImg)\n",
    "        regions = regionprops(label_halves)\n",
    "\n",
    "#         print (len(regions))\n",
    "\n",
    "        if len(regions) > 1:\n",
    "            regions_area1 = []\n",
    "\n",
    "            rathalf1 = regions[0]\n",
    "\n",
    "            y01, x01 = rathalf1.centroid\n",
    "            #calculating intersection points of bifurcating line with rat outline\n",
    "            #             x11 = x01 - math.cos(orient_ratBlob) * 0.5 * rathalf1.major_axis_length\n",
    "            #             y11 = y01 + math.sin(orient_ratBlob) * 0.5 * rathalf1.major_axis_length\n",
    "            x21 = x01 - math.sin(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            y21 = y01 - math.cos(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            x31 = x01 + math.sin(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            y31 = y01 + math.cos(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "\n",
    "            #drawing two lines next to each other to make a thicker line\n",
    "            rrh11, cch11 = line(int(y01), int(x01), int(y21), int(x21))\n",
    "            rrh12, cch12 = line(int(y01), int(x01), int(y31), int(x31))\n",
    "            rrh13, cch13 = line(int(y01)+1, int(x01), int(y21)+1, int(x21))\n",
    "            rrh14, cch14 = line(int(y01)+1, int(x01), int(y31)+1, int(x31))\n",
    "\n",
    "            #set color of lines to opaque black\n",
    "            set_color(ratOnlyImg, (rrh11, cch11), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh12, cch12), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh13, cch13), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh14, cch14), (0), 1)\n",
    "\n",
    "            # label foreground again into two quarters and a half\n",
    "            label_quarters1 = label(ratOnlyImg)\n",
    "            regions1 = regionprops(label_quarters1)\n",
    "#             for props1 in regions1:\n",
    "#                 if props1 not in regions:\n",
    "#                     regions_area1.append(props1)\n",
    "\n",
    "            for reg in regions:\n",
    "                if reg in regions1:\n",
    "                    regions1.remove(reg)\n",
    "\n",
    "            rathalf2 = regions[1]\n",
    "#             print (rathalf2)\n",
    "#             print (len(regions_area1))\n",
    "\n",
    "            ratquart1 = regions1[0]\n",
    "            ratquart2 = regions1[1]            \n",
    "            rqy1, rqx1 = ratquart1.centroid\n",
    "            rqy2, rqx2 = ratquart2.centroid \n",
    "\n",
    "            if dist_pts(rqx1, rqy1, x0, y0) > dist_pts(rqx2, rqy2, x0, y0):\n",
    "                hx1 = rqx1\n",
    "                hy1 = rqy1\n",
    "#                 cv2.circle(im,(int(hx1), int(hy1)),10,(255,255,255),-11)\n",
    "            else:\n",
    "                hx1 = rqx2\n",
    "                hy1 = rqy2\n",
    "#                 cv2.circle(im,(int(hx1), int(hy1)),10,(255,255,255),-11)\n",
    "\n",
    "\n",
    "            y02, x02 = rathalf2.centroid\n",
    "#             x12 = x02 - math.cos(orient_ratBlob) * 0.5 * rathalf2.major_axis_length\n",
    "#             y12 = y02 + math.sin(orient_ratBlob) * 0.5 * rathalf2.major_axis_length\n",
    "            x22 = x02 - math.sin(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            y22 = y02 - math.cos(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            x32 = x02 + math.sin(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            y32 = y02 + math.cos(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "\n",
    "            rrh21, cch21 = line(int(y02), int(x02), int(y22), int(x22))\n",
    "            rrh22, cch22 = line(int(y02), int(x02), int(y32), int(x32))\n",
    "            rrh23, cch23 = line(int(y02)+1, int(x02), int(y22)+1, int(x22))\n",
    "            rrh24, cch24 = line(int(y02)+1, int(x02), int(y32)+1, int(x32))\n",
    "\n",
    "            set_color(ratOnlyImg, (rrh21, cch21), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh22, cch22), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh23, cch23), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh24, cch24), (0), 1)\n",
    "\n",
    "            label_quarters2 = label(ratOnlyImg)\n",
    "            regions2 = regionprops(label_quarters2)            \n",
    "\n",
    "            for reg in regions1:\n",
    "                if reg in regions2:\n",
    "                    regions2.remove(reg)\n",
    "#             print (len(regions2))\n",
    "            #             print(len(regions2))\n",
    "            ratquart3 = regions2[0]\n",
    "            ratquart4 = regions2[1]\n",
    "            rqy3, rqx3 = ratquart3.centroid\n",
    "            rqy4, rqx4 = ratquart4.centroid\n",
    "\n",
    "            if dist_pts(rqx3, rqy3, x0, y0) > dist_pts(rqx4, rqy4, x0, y0):\n",
    "                hx2 = rqx3\n",
    "                hy2 = rqy3\n",
    "#                 cv2.circle(im,(int(hx2), int(hy2)),10,(0,0,255),-11)\n",
    "\n",
    "            else:\n",
    "                hx2 = rqx4\n",
    "                hy2 = rqy4\n",
    "#                 cv2.circle(im,(int(hx2), int(hy2)),10,(0,0,255),-11)\n",
    "\n",
    "            #closest to previous frame AND change isn't greater than half the length of the rat\n",
    "            if dist_pts(hx1, hy1, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "                > dist_pts(hx2, hy2, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]):\n",
    "#                 position.coordinates[i, : ] = [hx2, hy2]\n",
    "                if dist_pts(hx2, hy2, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "                    < dist_pts(x1,y1,x0,y0):\n",
    "                    position.coordinates[i, :] = [hx2, hy2]\n",
    "                else:\n",
    "                    position.coordinates[i, :] = [hx1, hy1]\n",
    "            else:\n",
    "                if dist_pts(hx1, hy1, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "                    < dist_pts(x1,y1,x0,y0):\n",
    "                    position.coordinates[i, :] = [hx1, hy1]\n",
    "                else:\n",
    "                    position.coordinates[i, : ] = [hx2, hy2]\n",
    "\n",
    "#             if dist_pts(hx2, hy2, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "#                     < dist_pts(x1,y1,x0,y0):\n",
    "#                 position.coordinates[i, :] = [hx2, hy2]\n",
    "#             else:\n",
    "#                 position.coordinates[i, :] = [hx1, hy1]\n",
    "\n",
    "            if position.click:\n",
    "                cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),10,(255,255,255),-11)\n",
    "                cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),11,(0,0,255),1) # draw circle\n",
    "                cv2.ellipse(im, (int(position.clickcoords[0]),int(position.clickcoords[1])), (10,10), 0, 0, 90,(0,255,255),-1 )\n",
    "                cv2.ellipse(im, (int(position.clickcoords[0]),int(position.clickcoords[1])), (10,10), 0, 180, 270,(0,255,255),-1 )\n",
    "                cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),1,(0,255,0),1) # draw center\n",
    "                position.click = False\n",
    "            else:\n",
    "                #draw tracking \"dot\"\n",
    "                cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),10,(255,255,255),-11)\n",
    "                cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),11,(0,0,255),1) # draw circle\n",
    "                cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "                cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "                cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),1,(0,255,0),1) # draw center\n",
    "      \n",
    "        \n",
    "#     cv2.imshow('fgmask',fgmask)\n",
    "#     cv2.imshow('im',im)\n",
    "#     cv2.imshow('bg',bg)\n",
    "    cv2.imshow('bbox', im2)\n",
    "    \n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "            \n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why not only focus on the ratblob as opposed to the entire foreground when bifurcating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<b>Update:</b> This is apparently what Etienne was doing and I am now stealing his implementation of 3 lines...funny how we came to the same idea separately guess the INT parts of our personalities are similar but we can J vs P at another time ;). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Modifications: </b>\n",
    "</div>\n",
    "- removing things from the fgmask that we don't care about (aka everything outside of the rat blob\n",
    "- setting a threshold for frame to frame change allowed for the head tracker limited to less than half the distance of the rat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>This works for Remi and Cavaradossi Novel Object Test videos once the background model is well trained!</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check around frame 6300-6400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video file length is 1058.4666666666667 seconds\n",
      "input video file has a framerate of 30.0 fps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31754it [02:26, 216.20it/s]\n"
     ]
    }
   ],
   "source": [
    "            #File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader(filename)\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "counter = 0\n",
    "\n",
    "for i, im in tqdm(enumerate(reader)):\n",
    "    counter += 1\n",
    "    if not (i%60):\n",
    "        im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "        im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "        writer.append_data(im)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "            #File IO\n",
    "numFrames_FamiliarObject = 0\n",
    "numFrames_NovelObject = 0\n",
    "reader = imageio.get_reader(filename)\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('test-out.mp4', fps=fps)\n",
    "\n",
    "\n",
    "topleft = []\n",
    "bottomright = []\n",
    "headpositions = []\n",
    "counter = 0\n",
    "\n",
    "refPt = []\n",
    "\n",
    "# def click(event, x, y, flags, param):\n",
    "#     # gra\n",
    "# b references to the global variables\n",
    "#     global refPt\n",
    "    \n",
    "#     # if the left mouse button was clicked, record the starting\n",
    "#     # (x, y) coordinates and indicate that cropping is being\n",
    "#     # performed\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         refPt = [(x, y)]\n",
    "#         posx = refPt[0]\n",
    "#         posy = refPt[1]\n",
    "#         return posx, posy\n",
    "\n",
    "# click(cv2.EVENT_LBUTTONDOWN)\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, m, n):\n",
    "        self.coordinates = np.zeros((m, n))\n",
    "        self.click = False\n",
    "\n",
    "    def select_coordinates(self, event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            #Set coordinates to mouse position\n",
    "            self.coordinates[i, :] = [x, y]\n",
    "            self.clickcoords = [x,y]\n",
    "            print (self.clickcoords[0], self.clickcoords[1])\n",
    "            self.click = True\n",
    "position = Position(reader.get_length(), 2)\n",
    "cv2.namedWindow('bbox', flags=cv2.WINDOW_AUTOSIZE)\n",
    "cv2.setMouseCallback('bbox', position.select_coordinates)\n",
    "\n",
    "\n",
    "centers1 = {}\n",
    "centers2 = {}\n",
    "\n",
    "def dist_pts(y,x,yy,xx):\n",
    "#     ht = (int(yy)-int(y))**2\n",
    "#     wdth = (int(xx)-int(x))**2\n",
    "#     if ht == 0:\n",
    "#         dist = int(xx) - int(x)\n",
    "#     elif wdth == 0:\n",
    "#         dist = int(yy) - int(y)\n",
    "#     else:\n",
    "#         dist = math.sqrt(ht/wdth)\n",
    "    dist = math.hypot(xx - x, yy - y)\n",
    "    return dist\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "\n",
    "for i, im in tqdm(enumerate(reader)):\n",
    "    counter += 1\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    #im = im[10:470, 20:480]\n",
    "    if learnBG:\n",
    "        fgmask = fgbg.apply(im)\n",
    "    else:\n",
    "        fgmask = fgbg.apply(im, learningRate=0)\n",
    "    \n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8*morph_size,8*morph_size)))\n",
    "    bg = fgbg.getBackgroundImage()\n",
    "    \n",
    "    #just need something of the same size\n",
    "    ratOnlyImg = fgmask\n",
    "    \n",
    "    # see https://www.mathworks.com/matlabcentral/answers/68696-how-can-i-extract-the-largest-blob-in-a-binary-image\n",
    "    label_img = label(fgmask)\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    region_areas = []\n",
    "    \n",
    "    for props in regions:\n",
    "        region_areas.append(props.area)\n",
    "    \n",
    "    if len(region_areas) > 0:\n",
    "        largestBlobIndex, _ = max(enumerate(region_areas), key=operator.itemgetter(1))\n",
    "        \n",
    "        # Find largest object in foreground\n",
    "        ratBlob = regions[largestBlobIndex]\n",
    "        \n",
    "        ybox2, xbox2, ybox1, xbox1 = ratBlob.bbox\n",
    "        im2 = cv2.rectangle(im, (xbox1, ybox1), (xbox2, ybox2), (255,255,255))\n",
    "        im2 = cv2.circle(im, (xbox1, ybox1), 2, (255,0,0))\n",
    "        im2 = cv2.circle(im, (xbox2, ybox2), 2, (0,0,255))\n",
    "        \n",
    "\n",
    "        #really the only new thing added is here...\n",
    "        #we don't care about anything other than the ratblob so let's 0 them everything else!\n",
    "        ratOnlyImg[:] = 0\n",
    "        for px in ratBlob.coords:\n",
    "            ratOnlyImg[px[0],px[1]] = 255\n",
    "\n",
    "        # Find center coordinates of largest foreground object\n",
    "        y0, x0 = ratBlob.centroid\n",
    "        cv2.circle(im,(int(x0), int(y0)),10,(255,0,0),-11)\n",
    "        # Find angle between x axis and major axis of an ellipse around largest foreground object\n",
    "        orient_ratBlob = ratBlob.orientation\n",
    "\n",
    "        # Find coordinates of endpoints of major axis\n",
    "        x1 = x0 + math.cos(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "        y1 = y0 - math.sin(orient_ratBlob) * 0.5 * ratBlob.major_axis_length\n",
    "        x2 = x0 - math.sin(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        y2 = y0 - math.cos(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        x3 = x0 + math.sin(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "        y3 = y0 + math.cos(orient_ratBlob) * 0.75 * ratBlob.minor_axis_length\n",
    "\n",
    "        rr1, cc1 = line(int(y0), int(x0), int(y2), int(x2))\n",
    "        rr2, cc2 = line(int(y0), int(x0), int(y3), int(x3))\n",
    "        rr3, cc3 = line(int(y0)+1, int(x0), int(y2)+1, int(x2))\n",
    "        rr4, cc4 = line(int(y0)+1, int(x0), int(y3)+1, int(x3))\n",
    "\n",
    "        set_color(ratOnlyImg, (rr1, cc1), (0), 1)\n",
    "        set_color(ratOnlyImg, (rr2, cc2), (0), 1)\n",
    "        set_color(ratOnlyImg, (rr3, cc3), (0), 1)\n",
    "        set_color(ratOnlyImg, (rr4, cc4), (0), 1)\n",
    "\n",
    "\n",
    "        label_halves = label(ratOnlyImg)\n",
    "        regions = regionprops(label_halves)\n",
    "\n",
    "#         print (len(regions))\n",
    "\n",
    "        if len(regions) > 1:\n",
    "            regions_area1 = []\n",
    "\n",
    "            rathalf1 = regions[0]\n",
    "\n",
    "            y01, x01 = rathalf1.centroid\n",
    "            #calculating intersection points of bifurcating line with rat outline\n",
    "            #             x11 = x01 - math.cos(orient_ratBlob) * 0.5 * rathalf1.major_axis_length\n",
    "            #             y11 = y01 + math.sin(orient_ratBlob) * 0.5 * rathalf1.major_axis_length\n",
    "            x21 = x01 - math.sin(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            y21 = y01 - math.cos(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            x31 = x01 + math.sin(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "            y31 = y01 + math.cos(orient_ratBlob) * 1.5 * rathalf1.minor_axis_length\n",
    "\n",
    "            #drawing two lines next to each other to make a thicker line\n",
    "            rrh11, cch11 = line(int(y01), int(x01), int(y21), int(x21))\n",
    "            rrh12, cch12 = line(int(y01), int(x01), int(y31), int(x31))\n",
    "            rrh13, cch13 = line(int(y01)+1, int(x01), int(y21)+1, int(x21))\n",
    "            rrh14, cch14 = line(int(y01)+1, int(x01), int(y31)+1, int(x31))\n",
    "\n",
    "            #set color of lines to opaque black\n",
    "            set_color(ratOnlyImg, (rrh11, cch11), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh12, cch12), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh13, cch13), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh14, cch14), (0), 1)\n",
    "\n",
    "            # label foreground again into two quarters and a half\n",
    "            label_quarters1 = label(ratOnlyImg)\n",
    "            regions1 = regionprops(label_quarters1)\n",
    "#             for props1 in regions1:\n",
    "#                 if props1 not in regions:\n",
    "#                     regions_area1.append(props1)\n",
    "\n",
    "            for reg in regions:\n",
    "                if reg in regions1:\n",
    "                    regions1.remove(reg)\n",
    "\n",
    "            rathalf2 = regions[1]\n",
    "#             print (rathalf2)\n",
    "#             print (len(regions_area1))\n",
    "\n",
    "            ratquart1 = regions1[0]\n",
    "            ratquart2 = regions1[1]            \n",
    "            rqy1, rqx1 = ratquart1.centroid\n",
    "            rqy2, rqx2 = ratquart2.centroid \n",
    "\n",
    "            if dist_pts(rqx1, rqy1, x0, y0) > dist_pts(rqx2, rqy2, x0, y0):\n",
    "                hx1 = rqx1\n",
    "                hy1 = rqy1\n",
    "#                 cv2.circle(im,(int(hx1), int(hy1)),10,(255,255,255),-11)\n",
    "            else:\n",
    "                hx1 = rqx2\n",
    "                hy1 = rqy2\n",
    "#                 cv2.circle(im,(int(hx1), int(hy1)),10,(255,255,255),-11)\n",
    "\n",
    "\n",
    "            y02, x02 = rathalf2.centroid\n",
    "#             x12 = x02 - math.cos(orient_ratBlob) * 0.5 * rathalf2.major_axis_length\n",
    "#             y12 = y02 + math.sin(orient_ratBlob) * 0.5 * rathalf2.major_axis_length\n",
    "            x22 = x02 - math.sin(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            y22 = y02 - math.cos(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            x32 = x02 + math.sin(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "            y32 = y02 + math.cos(orient_ratBlob) * 1.5 * rathalf2.minor_axis_length\n",
    "\n",
    "            rrh21, cch21 = line(int(y02), int(x02), int(y22), int(x22))\n",
    "            rrh22, cch22 = line(int(y02), int(x02), int(y32), int(x32))\n",
    "            rrh23, cch23 = line(int(y02)+1, int(x02), int(y22)+1, int(x22))\n",
    "            rrh24, cch24 = line(int(y02)+1, int(x02), int(y32)+1, int(x32))\n",
    "\n",
    "            set_color(ratOnlyImg, (rrh21, cch21), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh22, cch22), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh23, cch23), (0), 1)\n",
    "            set_color(ratOnlyImg, (rrh24, cch24), (0), 1)\n",
    "\n",
    "            label_quarters2 = label(ratOnlyImg)\n",
    "            regions2 = regionprops(label_quarters2)            \n",
    "\n",
    "            for reg in regions1:\n",
    "                if reg in regions2:\n",
    "                    regions2.remove(reg)\n",
    "#             print (len(regions2))\n",
    "            #             print(len(regions2))\n",
    "            ratquart3 = regions2[0]\n",
    "            ratquart4 = regions2[1]\n",
    "            rqy3, rqx3 = ratquart3.centroid\n",
    "            rqy4, rqx4 = ratquart4.centroid\n",
    "\n",
    "            if dist_pts(rqx3, rqy3, x0, y0) > dist_pts(rqx4, rqy4, x0, y0):\n",
    "                hx2 = rqx3\n",
    "                hy2 = rqy3\n",
    "#                 cv2.circle(im,(int(hx2), int(hy2)),10,(0,0,255),-11)\n",
    "\n",
    "            else:\n",
    "                hx2 = rqx4\n",
    "                hy2 = rqy4\n",
    "#                 cv2.circle(im,(int(hx2), int(hy2)),10,(0,0,255),-11)\n",
    "\n",
    "            #closest to previous frame AND change isn't greater than half the length of the rat\n",
    "            if dist_pts(hx1, hy1, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "                > dist_pts(hx2, hy2, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]):\n",
    "#                 position.coordinates[i, : ] = [hx2, hy2]\n",
    "                if dist_pts(hx2, hy2, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "                    < dist_pts(x1,y1,x0,y0):\n",
    "                    position.coordinates[i, :] = [hx2, hy2]\n",
    "                else:\n",
    "                    position.coordinates[i, :] = [hx1, hy1]\n",
    "            else:\n",
    "                if dist_pts(hx1, hy1, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "                    < dist_pts(x1,y1,x0,y0):\n",
    "                    position.coordinates[i, :] = [hx1, hy1]\n",
    "                else:\n",
    "                    position.coordinates[i, : ] = [hx2, hy2]\n",
    "\n",
    "#             if dist_pts(hx2, hy2, position.coordinates[i - 1, 0], position.coordinates[i - 1, 1]) \\\n",
    "#                     < dist_pts(x1,y1,x0,y0):\n",
    "#                 position.coordinates[i, :] = [hx2, hy2]\n",
    "#             else:\n",
    "#                 position.coordinates[i, :] = [hx1, hy1]\n",
    "\n",
    "#             if position.click:\n",
    "#                 cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),10,(255,255,255),-11)\n",
    "#                 cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),11,(0,0,255),1) # draw circle\n",
    "#                 cv2.ellipse(im, (int(position.clickcoords[0]),int(position.clickcoords[1])), (10,10), 0, 0, 90,(0,255,255),-1 )\n",
    "#                 cv2.ellipse(im, (int(position.clickcoords[0]),int(position.clickcoords[1])), (10,10), 0, 180, 270,(0,255,255),-1 )\n",
    "#                 cv2.circle(im,(int(position.clickcoords[0]),int(position.clickcoords[1])),1,(0,255,0),1) # draw center\n",
    "#                 headpositions.append((int(position.clickcoords[0]),int(position.clickcoords[1])))\n",
    "#                 position.click = False\n",
    "#             else:\n",
    "#                 #draw tracking \"dot\"\n",
    "#                 cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),10,(255,255,255),-11)\n",
    "#                 cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),11,(0,0,255),1) # draw circle\n",
    "#                 cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 0, 90,(0,0,255),-1 )\n",
    "#                 cv2.ellipse(im, (int(position.coordinates[i, 0]),int(position.coordinates[i, 1])), (10,10), 0, 180, 270,(0,0,255),-1 )\n",
    "#                 cv2.circle(im,(int(position.coordinates[i, 0]),int(position.coordinates[i, 1])),1,(0,255,0),1) # draw center\n",
    "                \n",
    "                \n",
    "#         if not (counter % 60):\n",
    "#             topleft.append(tuple([xbox1,ybox1]))\n",
    "#             bottomright.append(tuple([xbox2, ybox2]))\n",
    "#             if position.click:\n",
    "#                 headpositions.append((int(position.clickcoords[0]),int(position.clickcoords[1])))\n",
    "#             else:\n",
    "#                 headpositions.append((int(position.coordinates[i, 0]),int(position.coordinates[i, 1])))\n",
    "\n",
    "#         # 'dot' location of familiar object\n",
    "#         cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,0,0),10) \n",
    "\n",
    "#         # 'dot' location of novel object\n",
    "#         cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,0,0),10) \n",
    "\n",
    "        realWorldPoint = cv2.perspectiveTransform(np.array([np.array([[position.coordinates[i, 0],position.coordinates[i, 1]]],dtype='float32')]), homography_matrix)\n",
    "        realWorldX = realWorldPoint[0][0][0]\n",
    "        realWorldY = realWorldPoint[0][0][1]\n",
    "\n",
    "#         distanceFromNovelObject = math.hypot(novelObject_center_x_realWorld - realWorldX, novelObject_center_y_realWorld - realWorldY)\n",
    "#         distanceFromFamiliarObject = math.hypot(familiarObject_center_x_realWorld - realWorldX, familiarObject_center_y_realWorld - realWorldY)\n",
    "#         if(distanceFromNovelObject < DistanceThrehshold_NovelObject):\n",
    "#             numFrames_NovelObject = numFrames_NovelObject + 1\n",
    "#             cv2.circle(im,(novelObject_center_x,novelObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "#         if(distanceFromFamiliarObject < DistanceThreshold_familiarObject):\n",
    "#             numFrames_FamiliarObject = numFrames_FamiliarObject + 1\n",
    "#             cv2.circle(im,(familiarObject_center_x,familiarObject_center_y),1,(0,255,0),10) \n",
    "\n",
    "\n",
    "#     cv2.imshow('fgmask',fgmask)\n",
    "    cv2.imshow('ratonly',ratOnlyImg)\n",
    "    cv2.imshow('bbox',im)\n",
    "    cv2.imshow('bg',bg)\n",
    "\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "\n",
    "    writer.append_data(im)\n",
    "#     print(k)\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#     print('k',k)\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "\n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "# print(\"Total amount of time spent with objects: {} seconds\".format((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps)))\n",
    "# print(\"Percentage of time spent with objects that was spent with the novel object: {}%\".format((numFrames_NovelObject*100/fps)/((numFrames_FamiliarObject/fps)+(numFrames_NovelObject/fps))))\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(10):\n",
    "    if ii < 5:\n",
    "        continue\n",
    "    print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = np.asarray(topleft)\n",
    "br = np.asarray(bottomright)\n",
    "headpos = np.asarray(headpositions)\n",
    "# len(tl)\n",
    "np.savez('/home/kemerelab/Ariel/NNTrackingVids/NOT1-cropped.npz',\\\n",
    "        tl = tl, br = br, headpos = headpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(60 % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 36.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video file length is 1829.1333333333334 seconds\n",
      "input video file has a framerate of 30.0 fps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2330it [00:38, 58.57it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1daedd99013a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# imageio writer takes RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#     print('k',k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#    if k!= 255:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reader = imageio.get_reader(filename)\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "writer = imageio.get_writer('/home/kemerelab/Ariel/NNTrackingVids/12-22-2016-1selective.mp4', fps=fps)\n",
    "\n",
    "#Read in file frame by frame. Perform position tracking background subtraction\n",
    "# cv2.morph_open\n",
    "for i, im in tqdm(enumerate(reader)):\n",
    "    im =  cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    if not (i % 60):\n",
    "        im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # imageio writer takes RGB\n",
    "        writer.append_data(im)\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "#     print('k',k)\n",
    "#    if k!= 255:\n",
    "#        print(k)\n",
    "    if k == 32: # 'space'\n",
    "        if learnBG:\n",
    "            learnBG = False\n",
    "            print('background learning OFF')\n",
    "        else:\n",
    "            learnBG = True\n",
    "            print('background learning ON')\n",
    "    if k == 115: # 's'\n",
    "        if showShadow:\n",
    "            showShadow = False\n",
    "            shadowValue = 0\n",
    "            print('shadows OFF')\n",
    "        else:\n",
    "            showShadow = True\n",
    "            shadowValue = 127\n",
    "            print('shadows ON')\n",
    "        #fgbg.setDetectShadows(showShadow)\n",
    "        fgbg.setShadowValue(shadowValue)\n",
    "\n",
    "    if k == 171 or k == 43: # '+'\n",
    "        if morph_size < 20:\n",
    "            morph_size +=5\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 173 or k == 45: # '-'\n",
    "        if morph_size > 2:\n",
    "            morph_size -=1\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(morph_size,morph_size))\n",
    "    if k == 27:\n",
    "        break\n",
    "writer.close()\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video file length is 9.9 seconds\n",
      "input video file has a framerate of 30.0 fps\n",
      "frame number: 267\n",
      "596 437\n",
      "647 592\n",
      "624 458\n",
      "frame number: 268\n",
      "594 431\n",
      "644 590\n",
      "621 462\n",
      "frame number: 269\n",
      "596 448\n",
      "636 595\n",
      "624 482\n",
      "frame number: 270\n",
      "636 435\n",
      "619 612\n",
      "636 475\n",
      "frame number: 271\n",
      "641 440\n",
      "607 591\n",
      "639 480\n",
      "frame number: 272\n",
      "656 448\n",
      "622 601\n",
      "645 480\n",
      "frame number: 273\n",
      "640 452\n",
      "618 600\n",
      "635 485\n",
      "frame number: 274\n",
      "630 450\n",
      "624 580\n",
      "641 484\n",
      "frame number: 275\n",
      "587 433\n",
      "647 579\n",
      "612 461\n",
      "frame number: 276\n",
      "586 435\n",
      "638 600\n",
      "615 454\n",
      "frame number: 277\n",
      "586 465\n",
      "637 597\n",
      "609 445\n",
      "frame number: 278\n",
      "589 498\n",
      "649 582\n",
      "605 435\n",
      "frame number: 279\n",
      "607 473\n",
      "647 606\n",
      "644 505\n",
      "frame number: 280\n",
      "594 493\n",
      "679 570\n",
      "662 526\n",
      "frame number: 281\n",
      "598 487\n",
      "680 563\n",
      "659 518\n",
      "frame number: 282\n",
      "592 395\n",
      "633 553\n",
      "617 424\n",
      "frame number: 283\n",
      "584 371\n",
      "643 534\n",
      "609 398\n",
      "frame number: 284\n",
      "584 377\n",
      "635 533\n",
      "614 402\n",
      "frame number: 285\n",
      "586 383\n",
      "635 549\n",
      "616 408\n",
      "frame number: 286\n",
      "585 371\n",
      "646 542\n",
      "618 411\n",
      "frame number: 287\n",
      "660 361\n",
      "621 507\n",
      "659 399\n",
      "frame number: 288\n",
      "667 362\n",
      "618 494\n",
      "656 402\n",
      "frame number: 289\n",
      "662 364\n",
      "622 504\n",
      "652 400\n",
      "frame number: 290\n",
      "622 347\n",
      "634 500\n",
      "642 385\n",
      "frame number: 291\n",
      "595 306\n",
      "637 460\n",
      "616 339\n",
      "frame number: 292\n",
      "636 179\n",
      "642 352\n",
      "651 215\n",
      "frame number: 293\n",
      "578 138\n",
      "665 262\n",
      "610 160\n",
      "frame number: 294\n",
      "762 154\n",
      "898 263\n",
      "879 220\n",
      "frame number: 295\n",
      "809 185\n",
      "918 307\n",
      "889 282\n",
      "frame number: 296\n",
      "1037 131\n",
      "978 255\n",
      "1044 167\n",
      "exited gracefully\n"
     ]
    }
   ],
   "source": [
    "reader = imageio.get_reader(filename)\n",
    "fps = reader.get_meta_data()['fps']\n",
    "print('input video file length is {} seconds'.format(reader.get_length()/(fps)))\n",
    "print('input video file has a framerate of {} fps'.format(fps))\n",
    "\n",
    "# topleft = []\n",
    "# bottomright = []\n",
    "# headpositions = []\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, m, n):\n",
    "        self.coordinates = np.zeros((m, n))\n",
    "        self.click = False\n",
    "\n",
    "    def select_coordinates(self, event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            #Set coordinates to mouse position\n",
    "            self.coordinates[i, :] = [x, y]\n",
    "            self.clickcoords = [x,y]\n",
    "            print (self.clickcoords[0], self.clickcoords[1])\n",
    "            self.click = True\n",
    "position = Position(reader.get_length(), 2)\n",
    "cv2.namedWindow('bbox', flags=cv2.WINDOW_AUTOSIZE)\n",
    "cv2.setMouseCallback('bbox', position.select_coordinates)\n",
    "\n",
    "for i, im in enumerate(reader):\n",
    "    if i >= 267:\n",
    "        im =  cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('bbox',im)\n",
    "        print('frame number:', i)\n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        topleft.append(tuple((int(position.clickcoords[0]),int(position.clickcoords[1]))))\n",
    "        position.clickcoords=[]\n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        bottomright.append(tuple((int(position.clickcoords[0]),int(position.clickcoords[1]))))\n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        headpositions.append(tuple((int(position.clickcoords[0]),int(position.clickcoords[1]))))\n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "print('exited gracefully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topleft.pop(-1)\n",
    "tl = np.asarray(topleft)\n",
    "br = np.asarray(bottomright)\n",
    "headpos = np.asarray(headpositions)\n",
    "np.savez('/home/kemerelab/Ariel/NNTrackingVids/12-22-2016-1round2.npz',\\\n",
    "        tl = tl, br = br, headpos = headpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((267, 2), (267, 2), (267, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.shape, headpos.shape, br.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
